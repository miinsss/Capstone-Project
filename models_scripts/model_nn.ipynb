{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul8FG0MadDKn"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3ZcHUY1On1h"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7444,
     "status": "ok",
     "timestamp": 1717012792434,
     "user": {
      "displayName": "Mina Randolf",
      "userId": "17262056063041429157"
     },
     "user_tz": -120
    },
    "id": "auzgWilTMYX6",
    "outputId": "75356e01-dcee-45ed-d820-ddb5a3a1455a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9UsEZkYznAS"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/ct286z0d1tz0s971c6b7qshh0000gn/T/ipykernel_14880/2924754066.py:3: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 11574439\n",
      "Column names: Index(['ANO_SID', 'CORPORATE_DEVISION', 'ORTPLZ', 'ORTS-NAME', 'STRASSE',\n",
      "       'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL',\n",
      "       'ZONE', 'SF-SYSTEM', 'TYPE_OF_DEDUCTIBLE', 'DRAIN_PIPE_INSURED',\n",
      "       'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'PARTY-ID',\n",
      "       'contract_year', 'PIPE_PREMIUM_AMOUNT', 'YEAR', 'DAMAGE', 'year'],\n",
      "      dtype='object')\n",
      "Column types: ANO_SID                       float64\n",
      "CORPORATE_DEVISION             object\n",
      "ORTPLZ                        float64\n",
      "ORTS-NAME                      object\n",
      "STRASSE                        object\n",
      "SUM_INSURED                   float64\n",
      "CONSTRACTION_DESIGN            object\n",
      "CONSTRUCTION_YEAR             float64\n",
      "WFL                           float64\n",
      "ZONE                           object\n",
      "SF-SYSTEM                     float64\n",
      "TYPE_OF_DEDUCTIBLE              int64\n",
      "DRAIN_PIPE_INSURED              int64\n",
      "PRODUCTLINE                    object\n",
      "PRIOR_DAMAGES                   int64\n",
      "UVV-KZ                          int64\n",
      "UNDERWRITER                    object\n",
      "PARTY-ID                       object\n",
      "contract_year          datetime64[ns]\n",
      "PIPE_PREMIUM_AMOUNT           float64\n",
      "YEAR                            int64\n",
      "DAMAGE                          int64\n",
      "year                            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = '/Users/minarandolf/Desktop/Capstone Project/contract_classification.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'contract_year' column to datetime\n",
    "df['contract_year'] = pd.to_datetime(df['contract_year'], format='%Y-%m-%d')\n",
    "df['year'] = df['contract_year'].dt.year\n",
    "\n",
    "# Ensure all categorical columns are treated as such\n",
    "categorical_columns = ['CORPORATE_DEVISION', 'ORTS-NAME', 'STRASSE', 'CONSTRACTION_DESIGN', 'ZONE', 'PRODUCTLINE', 'UNDERWRITER', 'PARTY-ID']\n",
    "df[categorical_columns] = df[categorical_columns].astype(str)\n",
    "\n",
    "print(f\"Number of observations: {len(df)}\")\n",
    "print(\"Column names:\", df.columns)\n",
    "print(\"Column types:\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G08M52oQSV3"
   },
   "source": [
    "## Define Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PEzx7Qu3Pb-g"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Handle missing values\n",
    "    df.fillna('missing', inplace=True)\n",
    "\n",
    "    # Convert categorical columns to dummy variables\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop('DAMAGE', axis=1)\n",
    "    y = df['DAMAGE']\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwxXODW2YInA"
   },
   "source": [
    "## Define Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NlkJuSRE5QoX"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Window Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjuqV_8yYJDn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/ct286z0d1tz0s971c6b7qshh0000gn/T/ipykernel_14880/2688782636.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna('missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "years = sorted(df['year'].unique())\n",
    "\n",
    "recall_scores = []\n",
    "\n",
    "for i in range(len(years) - 1):\n",
    "    train_year = years[i]\n",
    "    test_year = years[i + 1]\n",
    "\n",
    "    train_df = df[df['year'] == train_year]\n",
    "    test_df = df[df['year'] == test_year]\n",
    "\n",
    "    X_train, y_train = preprocess_data(train_df)\n",
    "    X_test, y_test = preprocess_data(test_df)\n",
    "\n",
    "    # Convert to TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model(X_train.shape[1])\n",
    "    model.fit(train_dataset, epochs=10, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, recall = model.evaluate(test_dataset, verbose=1)\n",
    "    print(f\"Year {train_year} to {test_year} - Recall: {recall:.4f}\")\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "print(\"Average Recall over all years:\", np.mean(recall_scores))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmMzAS4WpZmv4I8SMs6BeT",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
