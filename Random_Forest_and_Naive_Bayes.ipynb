{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miinsss/Capstone-Project/blob/main/Random_Forest_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bU5iM6J_2o"
      },
      "source": [
        "# Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENHreirWKFF9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbf_dBkuKPCj"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LksDbqsQKVuC",
        "outputId": "4ea06f38-e0d6-4bfb-f2b2-d660c85b6795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-56a844a11275>:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  contract_class = pd.read_csv(contract_class_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ANO_SID CORPORATE_DEVISION   ORTPLZ  ORTS-NAME               STRASSE  \\\n",
            "0  4114028.0                VHV  42109.0  Wuppertal     Hans-Böckler-Str.   \n",
            "1  4114039.0                VHV  42277.0  Wuppertal       Liegnitzer Str.   \n",
            "2  4114045.0                VHV  42389.0  Wuppertal             Rascheweg   \n",
            "3  4114049.0                VGV  42277.0  Wuppertal               Am Diek   \n",
            "4  4114055.0                VHV  42553.0    Velbert  Emil-Schniewind-Str.   \n",
            "\n",
            "   SUM_INSURED CONSTRACTION_DESIGN  CONSTRUCTION_YEAR        WFL ZONE  ...  \\\n",
            "0      71081.0      NORMAL_VENTURE        1967.565648   69.00000  2.0  ...   \n",
            "1      55708.0      NORMAL_VENTURE        1967.565648   65.00000  4.0  ...   \n",
            "2      74148.0      DESIGN_CLASS_I        1967.565648   75.00000  1.0  ...   \n",
            "3     664000.0      NORMAL_VENTURE        1967.565648  106.24368  NaN  ...   \n",
            "4      75682.0      NORMAL_VENTURE        1967.565648  119.00000  2.0  ...   \n",
            "\n",
            "   DRAIN_PIPE_INSURED  PRODUCTLINE  PRIOR_DAMAGES UVV-KZ  UNDERWRITER  \\\n",
            "0                   0        Sonst              0      1            Y   \n",
            "1                   0        Basis              0      1            Y   \n",
            "2                   0        Sonst              0      1            Y   \n",
            "3                   0      Kompakt              0      1            Y   \n",
            "4                   0        Sonst              0      1            Y   \n",
            "\n",
            "               PARTY-ID contract_year PIPE_PREMIUM_AMOUNT  YEAR  DAMAGE  \n",
            "0  N00WXYAWXFD704PT4712    2014-01-01             4.55070  2014       0  \n",
            "1  YH8XZ8AWXFD704PT4713    2014-01-01             4.54080  2014       0  \n",
            "2  AIPAVQEWXFD704PT4713    2014-01-01             3.18120  2014       0  \n",
            "3  GG0UA4KWXFD704PT4715    2014-01-01           154.60908  2014       0  \n",
            "4  P6XU2FAWXFD704PT4712    2014-01-01             5.89380  2014       0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the contract_classification.csv file\n",
        "contract_class_path = '/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/contract_classification.csv'\n",
        "contract_class = pd.read_csv(contract_class_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify content\n",
        "print(contract_class.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3k-fugN17z",
        "outputId": "cbf8e941-aa86-4194-f408-2e40ccedd30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "ANO_SID                     55\n",
            "CORPORATE_DEVISION           0\n",
            "ORTPLZ                  102482\n",
            "ORTS-NAME                 3901\n",
            "STRASSE                  16338\n",
            "SUM_INSURED              16503\n",
            "CONSTRACTION_DESIGN    1188450\n",
            "CONSTRUCTION_YEAR            0\n",
            "WFL                      16670\n",
            "ZONE                    988470\n",
            "SF-SYSTEM              9717058\n",
            "TYPE_OF_DEDUCTIBLE           0\n",
            "DRAIN_PIPE_INSURED           0\n",
            "PRODUCTLINE            1735746\n",
            "PRIOR_DAMAGES                0\n",
            "UVV-KZ                       0\n",
            "UNDERWRITER                  0\n",
            "PARTY-ID                   203\n",
            "contract_year                0\n",
            "PIPE_PREMIUM_AMOUNT        167\n",
            "YEAR                         0\n",
            "DAMAGE                       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(contract_class['DAMAGE'].value_counts())\n",
        "\n",
        "# Assuming your DataFrame is named contract_class\n",
        "na_counts = contract_class.isna().sum()\n",
        "\n",
        "print(na_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoya1IqoQlP9"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKlJomDBmkF0"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWuhhszlQyyR",
        "outputId": "af2989c2-44a8-4170-fb62-68cec0a8cebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "DAMAGE\n",
            "0    8516533\n",
            "1     120574\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Choose variables where it makes logical sense\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE']]\n",
        "\n",
        "print(initial_features['DAMAGE'].value_counts())\n",
        "\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "print(initial_features_clean['DAMAGE'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fTOzfKS3VKM",
        "outputId": "d9b41f7b-1dbd-4c64-e914-0b8a514a4a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ORTPLZ  SUM_INSURED  CONSTRUCTION_YEAR    WFL  DRAIN_PIPE_INSURED  \\\n",
            "0  42109.0      71081.0        1967.565648   69.0                   0   \n",
            "1  42277.0      55708.0        1967.565648   65.0                   0   \n",
            "2  42389.0      74148.0        1967.565648   75.0                   0   \n",
            "4  42553.0      75682.0        1967.565648  119.0                   0   \n",
            "5  42113.0      70000.0        1967.565648  100.0                   0   \n",
            "\n",
            "   PRIOR_DAMAGES  UVV-KZ  DAMAGE  CORPORATE_DEVISION_VHV  \\\n",
            "0              0       1       0                    True   \n",
            "1              0       1       0                    True   \n",
            "2              0       1       0                    True   \n",
            "4              0       1       0                    True   \n",
            "5              0       1       0                    True   \n",
            "\n",
            "   CONSTRACTION_DESIGN_CARAVAN_MOTORHOME  ...  ZONE_4  ZONE_4.0  ZONE_5  \\\n",
            "0                                  False  ...   False     False   False   \n",
            "1                                  False  ...   False     False   False   \n",
            "2                                  False  ...   False     False   False   \n",
            "4                                  False  ...   False     False   False   \n",
            "5                                  False  ...   False     False   False   \n",
            "\n",
            "   ZONE_5.0  ZONE_6  ZONE_6.0  ZONE_7  ZONE_7.0  ZONE_8  ZONE_8.0  \n",
            "0     False   False     False   False     False   False     False  \n",
            "1     False   False     False   False     False   False     False  \n",
            "2     False   False     False   False     False   False     False  \n",
            "4     False   False     False   False     False   False     False  \n",
            "5     False   False     False   False     False   False     False  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "print(features_binary.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwwN1Fk9-mx"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2tRFkvL99hn"
      },
      "outputs": [],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split into test and training\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize RandomUnderSampler\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJMfXDqqAZOZ"
      },
      "outputs": [],
      "source": [
        "# Initializing Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Training the classifier\n",
        "rf_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Making probability predictions\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vwjrTVhFXj",
        "outputId": "db2936ac-89c3-4d83-f1a2-9a17c0d2a03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7853703379950007\n",
            "Confusion Matrix:\n",
            "[[1338839  364364]\n",
            " [   6392   17827]]\n",
            "True Positives: 17827\n",
            "False Positives: 364364\n",
            "True Negatives: 1338839\n",
            "False Negatives: 6392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88   1703203\n",
            "           1       0.05      0.74      0.09     24219\n",
            "\n",
            "    accuracy                           0.79   1727422\n",
            "   macro avg       0.52      0.76      0.48   1727422\n",
            "weighted avg       0.98      0.79      0.87   1727422\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "\n",
        "# Converting probabilities to class predictions\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "# With undersampling accuracy gets worse, but we detect more TRUE Positives. Still way more false positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTixu8nHavRD",
        "outputId": "d116c686-4fd8-4b73-a80e-63c4d49056e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Importance:\n",
            "ORTPLZ: 0.22950934268938258\n",
            "SUM_INSURED: 0.3436387893280586\n",
            "CONSTRUCTION_YEAR: 0.10233732052560082\n",
            "WFL: 0.11902210383701167\n",
            "DRAIN_PIPE_INSURED: 0.0\n",
            "PRIOR_DAMAGES: 0.004227427149212484\n",
            "UVV-KZ: 0.014137294705900449\n",
            "CORPORATE_DEVISION_VHV: 0.1219592231461422\n",
            "CONSTRACTION_DESIGN_CARAVAN_MOTORHOME: 8.26432256751105e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_I: 0.00027824805381932284\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_II: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_III: 7.249581611118396e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_IV: 1.330879859145523e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_V: 2.0118167934125968e-07\n",
            "CONSTRACTION_DESIGN_NORMAL_VENTURE: 0.0010789227884194744\n",
            "CONSTRACTION_DESIGN_PREDOMINANTLY_WOODEN_ROOF: 0.00014440976673366968\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE: 0.0006388190920825517\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE_I: 0.0\n",
            "PRODUCTLINE_Kompakt: 0.0061697423506620365\n",
            "PRODUCTLINE_Plus: 0.001953922569924123\n",
            "PRODUCTLINE_Premium: 0.001659283059399923\n",
            "PRODUCTLINE_Sonst: 0.014688301109132768\n",
            "PRODUCTLINE_Top: 0.0034532815584079816\n",
            "UNDERWRITER_Y: 0.00526043325599241\n",
            "ZONE_1.0: 0.0024162436782179417\n",
            "ZONE_2.0: 0.0014661475168854295\n",
            "ZONE_3.0: 0.0013968164322887477\n",
            "ZONE_4.0: 0.0010030553762524442\n",
            "ZONE_5.0: 0.0006791113238424853\n",
            "ZONE_6.0: 0.00012018967707107168\n",
            "ZONE_7.0: 8.583349797855007e-05\n",
            "ZONE_8.0: 5.954968286178614e-05\n",
            "ZONE_0: 0.0007291135192884797\n",
            "ZONE_0.0: 3.965005856506764e-05\n",
            "ZONE_1: 0.006518653325393562\n",
            "ZONE_1.0: 0.00032333242775859044\n",
            "ZONE_2: 0.0022447366535717117\n",
            "ZONE_2.0: 0.0006406226005965495\n",
            "ZONE_3: 0.004975555266240754\n",
            "ZONE_3.0: 0.0006389249580279102\n",
            "ZONE_4: 0.003578866463324952\n",
            "ZONE_4.0: 0.0003907662936573053\n",
            "ZONE_5: 0.0017469485267464192\n",
            "ZONE_5.0: 0.00021870171941341975\n",
            "ZONE_6: 0.0002209353447939957\n",
            "ZONE_6.0: 9.800862116671537e-06\n",
            "ZONE_7: 0.00017161115981016917\n",
            "ZONE_7.0: 2.119429102096897e-05\n",
            "ZONE_8: 0.00012004779177105345\n",
            "ZONE_8.0: 9.68060090375542e-06\n"
          ]
        }
      ],
      "source": [
        "# Feature-importnace analysis\n",
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "# Display results\n",
        "print(\"Feature Importance:\")\n",
        "for i, feature in enumerate(X_train.columns):\n",
        "    print(f\"{feature}: {feature_importance[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhtW_D_ljQv"
      },
      "source": [
        "## Random Forest with Rolling window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mZ1DyNEoANN"
      },
      "outputs": [],
      "source": [
        "#Choose variables where it makes logical including year column\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE', 'YEAR']]\n",
        "\n",
        "initial_features_clean = initial_features.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pir7CO9ioRJd"
      },
      "outputs": [],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSk1hjJqoVi_",
        "outputId": "ab57990e-140a-4d2f-dcda-7733cdb20ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "YEAR_INDEX = features_binary.columns.get_loc('YEAR')\n",
        "print(YEAR_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "shjdeTf2l191",
        "outputId": "f3338e5b-30f7-4f0a-d2c1-910cef84f464"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [01:08<10:20, 68.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.46      0.28      0.35      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.73      0.64      0.67    785007\n",
            "weighted avg       0.98      0.99      0.99    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[772052   3219]\n",
            " [  6993   2743]]\n",
            "True Positives: 2743\n",
            "False Positives: 3219\n",
            "True Negatives: 772052\n",
            "False Negatives: 6993\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [02:21<09:30, 71.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.46      0.24      0.32     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.73      0.62      0.65    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[803211   3011]\n",
            " [  8219   2596]]\n",
            "True Positives: 2596\n",
            "False Positives: 3011\n",
            "True Negatives: 803211\n",
            "False Negatives: 8219\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [03:35<08:27, 72.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.48      0.23      0.31     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.74      0.61      0.65    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[759057   2612]\n",
            " [  8032   2427]]\n",
            "True Positives: 2427\n",
            "False Positives: 2612\n",
            "True Negatives: 759057\n",
            "False Negatives: 8032\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [04:44<07:05, 70.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.39      0.15      0.22     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.69      0.58      0.61    775789\n",
            "weighted avg       0.98      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[761545   2804]\n",
            " [  9682   1758]]\n",
            "True Positives: 1758\n",
            "False Positives: 2804\n",
            "True Negatives: 761545\n",
            "False Negatives: 9682\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [05:58<05:59, 71.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    771495\n",
            "           1       0.39      0.17      0.23     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.69      0.58      0.61    783975\n",
            "weighted avg       0.98      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[768278   3217]\n",
            " [ 10412   2068]]\n",
            "True Positives: 2068\n",
            "False Positives: 3217\n",
            "True Negatives: 768278\n",
            "False Negatives: 10412\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [07:17<04:57, 74.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    780559\n",
            "           1       0.39      0.16      0.23     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.69      0.58      0.61    794935\n",
            "weighted avg       0.97      0.98      0.98    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[776952   3607]\n",
            " [ 12049   2327]]\n",
            "True Positives: 2327\n",
            "False Positives: 3607\n",
            "True Negatives: 776952\n",
            "False Negatives: 12049\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [08:40<03:51, 77.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.37      0.15      0.21     15770\n",
            "\n",
            "    accuracy                           0.98    803868\n",
            "   macro avg       0.68      0.57      0.60    803868\n",
            "weighted avg       0.97      0.98      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[784070   4028]\n",
            " [ 13386   2384]]\n",
            "True Positives: 2384\n",
            "False Positives: 4028\n",
            "True Negatives: 784070\n",
            "False Negatives: 13386\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [10:02<02:37, 78.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    797092\n",
            "           1       0.30      0.14      0.19     13298\n",
            "\n",
            "    accuracy                           0.98    810390\n",
            "   macro avg       0.64      0.57      0.59    810390\n",
            "weighted avg       0.97      0.98      0.98    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[792603   4489]\n",
            " [ 11415   1883]]\n",
            "True Positives: 1883\n",
            "False Positives: 4489\n",
            "True Negatives: 792603\n",
            "False Negatives: 11415\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [11:25<01:20, 80.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    800711\n",
            "           1       0.26      0.11      0.15     11149\n",
            "\n",
            "    accuracy                           0.98    811860\n",
            "   macro avg       0.62      0.55      0.57    811860\n",
            "weighted avg       0.98      0.98      0.98    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[797130   3581]\n",
            " [  9921   1228]]\n",
            "True Positives: 1228\n",
            "False Positives: 3581\n",
            "True Negatives: 797130\n",
            "False Negatives: 9921\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [12:46<00:00, 76.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    806672\n",
            "           1       0.04      0.10      0.06      2049\n",
            "\n",
            "    accuracy                           0.99    808721\n",
            "   macro avg       0.52      0.55      0.53    808721\n",
            "weighted avg       1.00      0.99      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[801513   5159]\n",
            " [  1841    208]]\n",
            "True Positives: 208\n",
            "False Positives: 5159\n",
            "True Negatives: 801513\n",
            "False Negatives: 1841\n",
            "Year: 2015, Recall Score: 0.2817378800328677\n",
            "Year: 2016, Recall Score: 0.24003698566805362\n",
            "Year: 2017, Recall Score: 0.23204895305478535\n",
            "Year: 2018, Recall Score: 0.15367132867132868\n",
            "Year: 2019, Recall Score: 0.1657051282051282\n",
            "Year: 2020, Recall Score: 0.16186700055648304\n",
            "Year: 2021, Recall Score: 0.1511731135066582\n",
            "Year: 2022, Recall Score: 0.1416002406376899\n",
            "Year: 2023, Recall Score: 0.11014440757018566\n",
            "Year: 2024, Recall Score: 0.10151293313811616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTsXs3AgLwAE"
      },
      "source": [
        "## Random Forrest with expanding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZqoHusLLqif",
        "outputId": "31a34a80-30d8-4ff4-eb83-76a85fac884a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:15<02:16, 15.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    775271\n",
            "           1       0.39      0.29      0.33      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.69      0.64      0.66    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[770816   4455]\n",
            " [  6922   2814]]\n",
            "True Positives: 2814\n",
            "False Positives: 4455\n",
            "True Negatives: 770816\n",
            "False Negatives: 6922\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:44<03:09, 23.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.42      0.25      0.31     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.70      0.62      0.65    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[802504   3718]\n",
            " [  8161   2654]]\n",
            "True Positives: 2654\n",
            "False Positives: 3718\n",
            "True Negatives: 802504\n",
            "False Negatives: 8161\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:30<03:56, 33.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.43      0.24      0.30     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.71      0.62      0.65    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[758400   3269]\n",
            " [  7995   2464]]\n",
            "True Positives: 2464\n",
            "False Positives: 3269\n",
            "True Negatives: 758400\n",
            "False Negatives: 7995\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [02:31<04:26, 44.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.33      0.16      0.21     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.66      0.58      0.60    775789\n",
            "weighted avg       0.98      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[760678   3671]\n",
            " [  9633   1807]]\n",
            "True Positives: 1807\n",
            "False Positives: 3671\n",
            "True Negatives: 760678\n",
            "False Negatives: 9633\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [03:55<04:54, 58.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    771495\n",
            "           1       0.34      0.17      0.23     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.66      0.58      0.61    783975\n",
            "weighted avg       0.98      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767401   4094]\n",
            " [ 10361   2119]]\n",
            "True Positives: 2119\n",
            "False Positives: 4094\n",
            "True Negatives: 767401\n",
            "False Negatives: 10361\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [05:39<04:56, 74.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.35      0.17      0.23     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.67      0.58      0.61    794935\n",
            "weighted avg       0.97      0.98      0.98    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[776031   4528]\n",
            " [ 11960   2416]]\n",
            "True Positives: 2416\n",
            "False Positives: 4528\n",
            "True Negatives: 776031\n",
            "False Negatives: 11960\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [07:58<04:46, 95.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.33      0.16      0.21     15770\n",
            "\n",
            "    accuracy                           0.98    803868\n",
            "   macro avg       0.66      0.58      0.60    803868\n",
            "weighted avg       0.97      0.98      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[783011   5087]\n",
            " [ 13299   2471]]\n",
            "True Positives: 2471\n",
            "False Positives: 5087\n",
            "True Negatives: 783011\n",
            "False Negatives: 13299\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [10:27<03:44, 112.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    797092\n",
            "           1       0.24      0.15      0.19     13298\n",
            "\n",
            "    accuracy                           0.98    810390\n",
            "   macro avg       0.61      0.57      0.59    810390\n",
            "weighted avg       0.97      0.98      0.98    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[790580   6512]\n",
            " [ 11275   2023]]\n",
            "True Positives: 2023\n",
            "False Positives: 6512\n",
            "True Negatives: 790580\n",
            "False Negatives: 11275\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [13:32<02:14, 134.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    800711\n",
            "           1       0.23      0.12      0.16     11149\n",
            "\n",
            "    accuracy                           0.98    811860\n",
            "   macro avg       0.61      0.56      0.58    811860\n",
            "weighted avg       0.98      0.98      0.98    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[796005   4706]\n",
            " [  9761   1388]]\n",
            "True Positives: 1388\n",
            "False Positives: 4706\n",
            "True Negatives: 796005\n",
            "False Negatives: 9761\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [17:01<00:00, 102.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    806672\n",
            "           1       0.04      0.12      0.06      2049\n",
            "\n",
            "    accuracy                           0.99    808721\n",
            "   macro avg       0.52      0.55      0.53    808721\n",
            "weighted avg       1.00      0.99      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[800968   5704]\n",
            " [  1811    238]]\n",
            "True Positives: 238\n",
            "False Positives: 5704\n",
            "True Negatives: 800968\n",
            "False Negatives: 1811\n",
            "Year: 2015, Recall Score: 0.2890304026294166\n",
            "Year: 2016, Recall Score: 0.24539990753582985\n",
            "Year: 2017, Recall Score: 0.2355865761545081\n",
            "Year: 2018, Recall Score: 0.15795454545454546\n",
            "Year: 2019, Recall Score: 0.16979166666666667\n",
            "Year: 2020, Recall Score: 0.16805787423483584\n",
            "Year: 2021, Recall Score: 0.15668991756499684\n",
            "Year: 2022, Recall Score: 0.15212813956986013\n",
            "Year: 2023, Recall Score: 0.1244954704457799\n",
            "Year: 2024, Recall Score: 0.1161542215714983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(1, len(years))):\n",
        "    test_year = years[i]\n",
        "    train_years = years[:i]  # All years up to the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'].isin(train_years)]\n",
        "    y_train = y[features_binary['YEAR'].isin(train_years)]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNPRV0LutSjd"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXNnLuCbdc-T"
      },
      "outputs": [],
      "source": [
        "# Define initial features\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION', 'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL', 'ZONE', 'DRAIN_PIPE_INSURED', 'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'DAMAGE', 'YEAR']]\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "# Define feature and target\n",
        "columns_to_encode = ['CORPORATE_DEVISION', 'CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create binary variables using one-hot encoding\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate continuous and discrete features\n",
        "continuous_features = ['SUM_INSURED', 'CONSTRUCTION_YEAR']\n",
        "# The discrete features need to be adjusted after one-hot encoding\n",
        "discrete_features = list(set(X.columns) - set(continuous_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTjSjOWoF5u",
        "outputId": "00a0427a-d56c-415e-f6f2-1944c48c5d11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:03<00:27,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773616   1655]\n",
            " [  8536   1200]]\n",
            "True Positives: 1200\n",
            "False Positives: 1655\n",
            "True Negatives: 773616\n",
            "False Negatives: 8536\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:06<00:26,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.48      0.11      0.18     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.74      0.55      0.59    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804964   1258]\n",
            " [  9640   1175]]\n",
            "True Positives: 1175\n",
            "False Positives: 1258\n",
            "True Negatives: 804964\n",
            "False Negatives: 9640\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:09<00:22,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.42      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760286   1383]\n",
            " [  9455   1004]]\n",
            "True Positives: 1004\n",
            "False Positives: 1383\n",
            "True Negatives: 760286\n",
            "False Negatives: 9455\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:12<00:18,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.16      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762597   1752]\n",
            " [ 11106    334]]\n",
            "True Positives: 334\n",
            "False Positives: 1752\n",
            "True Negatives: 762597\n",
            "False Negatives: 11106\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:15<00:15,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    771495\n",
            "           1       0.09      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.54      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.97    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767538   3957]\n",
            " [ 12103    377]]\n",
            "True Positives: 377\n",
            "False Positives: 3957\n",
            "True Negatives: 767538\n",
            "False Negatives: 12103\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:18<00:12,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.08      0.03      0.05     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.53      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[775127   5432]\n",
            " [ 13900    476]]\n",
            "True Positives: 476\n",
            "False Positives: 5432\n",
            "True Negatives: 775127\n",
            "False Negatives: 13900\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:21<00:09,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98    788098\n",
            "           1       0.05      0.04      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.52      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[777761  10337]\n",
            " [ 15188    582]]\n",
            "True Positives: 582\n",
            "False Positives: 10337\n",
            "True Negatives: 777761\n",
            "False Negatives: 15188\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:24<00:06,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    797092\n",
            "           1       0.04      0.05      0.05     13298\n",
            "\n",
            "    accuracy                           0.96    810390\n",
            "   macro avg       0.51      0.52      0.51    810390\n",
            "weighted avg       0.97      0.96      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[780519  16573]\n",
            " [ 12590    708]]\n",
            "True Positives: 708\n",
            "False Positives: 16573\n",
            "True Negatives: 780519\n",
            "False Negatives: 12590\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:27<00:03,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98    800711\n",
            "           1       0.04      0.07      0.05     11149\n",
            "\n",
            "    accuracy                           0.96    811860\n",
            "   macro avg       0.51      0.52      0.51    811860\n",
            "weighted avg       0.97      0.96      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[779298  21413]\n",
            " [ 10356    793]]\n",
            "True Positives: 793\n",
            "False Positives: 21413\n",
            "True Negatives: 779298\n",
            "False Negatives: 10356\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98    806672\n",
            "           1       0.01      0.08      0.01      2049\n",
            "\n",
            "    accuracy                           0.96    808721\n",
            "   macro avg       0.50      0.52      0.49    808721\n",
            "weighted avg       1.00      0.96      0.98    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[775821  30851]\n",
            " [  1877    172]]\n",
            "True Positives: 172\n",
            "False Positives: 30851\n",
            "True Negatives: 775821\n",
            "False Negatives: 1877\n",
            "Year: 2015, Recall Score: 0.12325390304026294\n",
            "Year: 2016, Recall Score: 0.10864539990753583\n",
            "Year: 2017, Recall Score: 0.09599388086815183\n",
            "Year: 2018, Recall Score: 0.029195804195804195\n",
            "Year: 2019, Recall Score: 0.030208333333333334\n",
            "Year: 2020, Recall Score: 0.03311074012242626\n",
            "Year: 2021, Recall Score: 0.03690551680405834\n",
            "Year: 2022, Recall Score: 0.0532410888855467\n",
            "Year: 2023, Recall Score: 0.07112745537716388\n",
            "Year: 2024, Recall Score: 0.08394338701805759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "# Train GaussianNB on continuous features\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train[continuous_features], y_train)\n",
        "\n",
        "# Train MultinomialNB on discrete features\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train[discrete_features], y_train)\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srilci2A3lB6",
        "outputId": "f29d891b-722e-43a1-aee2-71b87d0b067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99   1719308\n",
            "           1       0.98      0.04      0.08     24428\n",
            "\n",
            "    accuracy                           0.99   1743736\n",
            "   macro avg       0.98      0.52      0.54   1743736\n",
            "weighted avg       0.99      0.99      0.98   1743736\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1719284      24]\n",
            " [  23369    1059]]\n",
            "True Positives: 1059\n",
            "False Positives: 24\n",
            "True Negatives: 1719284\n",
            "False Negatives: 23369\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNjBsFwxmFB_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOSDbTUH+IAzLb0yuj9oqmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}