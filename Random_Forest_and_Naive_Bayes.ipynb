{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNO8I20HBcO7fVHQtaGUto8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miinsss/Capstone-Project/blob/main/Random_Forest_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libaries"
      ],
      "metadata": {
        "id": "D6bU5iM6J_2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ENHreirWKFF9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "Sbf_dBkuKPCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the contract_classification.csv file\n",
        "contract_class_path = '/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/contract_classification.csv'\n",
        "contract_class = pd.read_csv(contract_class_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify content\n",
        "print(contract_class.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LksDbqsQKVuC",
        "outputId": "4ea06f38-e0d6-4bfb-f2b2-d660c85b6795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-56a844a11275>:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  contract_class = pd.read_csv(contract_class_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ANO_SID CORPORATE_DEVISION   ORTPLZ  ORTS-NAME               STRASSE  \\\n",
            "0  4114028.0                VHV  42109.0  Wuppertal     Hans-Böckler-Str.   \n",
            "1  4114039.0                VHV  42277.0  Wuppertal       Liegnitzer Str.   \n",
            "2  4114045.0                VHV  42389.0  Wuppertal             Rascheweg   \n",
            "3  4114049.0                VGV  42277.0  Wuppertal               Am Diek   \n",
            "4  4114055.0                VHV  42553.0    Velbert  Emil-Schniewind-Str.   \n",
            "\n",
            "   SUM_INSURED CONSTRACTION_DESIGN  CONSTRUCTION_YEAR        WFL ZONE  ...  \\\n",
            "0      71081.0      NORMAL_VENTURE        1967.565648   69.00000  2.0  ...   \n",
            "1      55708.0      NORMAL_VENTURE        1967.565648   65.00000  4.0  ...   \n",
            "2      74148.0      DESIGN_CLASS_I        1967.565648   75.00000  1.0  ...   \n",
            "3     664000.0      NORMAL_VENTURE        1967.565648  106.24368  NaN  ...   \n",
            "4      75682.0      NORMAL_VENTURE        1967.565648  119.00000  2.0  ...   \n",
            "\n",
            "   DRAIN_PIPE_INSURED  PRODUCTLINE  PRIOR_DAMAGES UVV-KZ  UNDERWRITER  \\\n",
            "0                   0        Sonst              0      1            Y   \n",
            "1                   0        Basis              0      1            Y   \n",
            "2                   0        Sonst              0      1            Y   \n",
            "3                   0      Kompakt              0      1            Y   \n",
            "4                   0        Sonst              0      1            Y   \n",
            "\n",
            "               PARTY-ID contract_year PIPE_PREMIUM_AMOUNT  YEAR  DAMAGE  \n",
            "0  N00WXYAWXFD704PT4712    2014-01-01             4.55070  2014       0  \n",
            "1  YH8XZ8AWXFD704PT4713    2014-01-01             4.54080  2014       0  \n",
            "2  AIPAVQEWXFD704PT4713    2014-01-01             3.18120  2014       0  \n",
            "3  GG0UA4KWXFD704PT4715    2014-01-01           154.60908  2014       0  \n",
            "4  P6XU2FAWXFD704PT4712    2014-01-01             5.89380  2014       0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(contract_class['DAMAGE'].value_counts())\n",
        "\n",
        "# Assuming your DataFrame is named contract_class\n",
        "na_counts = contract_class.isna().sum()\n",
        "\n",
        "print(na_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3k-fugN17z",
        "outputId": "cbf8e941-aa86-4194-f408-2e40ccedd30c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "ANO_SID                     55\n",
            "CORPORATE_DEVISION           0\n",
            "ORTPLZ                  102482\n",
            "ORTS-NAME                 3901\n",
            "STRASSE                  16338\n",
            "SUM_INSURED              16503\n",
            "CONSTRACTION_DESIGN    1188450\n",
            "CONSTRUCTION_YEAR            0\n",
            "WFL                      16670\n",
            "ZONE                    988470\n",
            "SF-SYSTEM              9717058\n",
            "TYPE_OF_DEDUCTIBLE           0\n",
            "DRAIN_PIPE_INSURED           0\n",
            "PRODUCTLINE            1735746\n",
            "PRIOR_DAMAGES                0\n",
            "UVV-KZ                       0\n",
            "UNDERWRITER                  0\n",
            "PARTY-ID                   203\n",
            "contract_year                0\n",
            "PIPE_PREMIUM_AMOUNT        167\n",
            "YEAR                         0\n",
            "DAMAGE                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "yoya1IqoQlP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data"
      ],
      "metadata": {
        "id": "hKlJomDBmkF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose variables where it makes logical sense\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE']]\n",
        "\n",
        "print(initial_features['DAMAGE'].value_counts())\n",
        "\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "print(initial_features_clean['DAMAGE'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWuhhszlQyyR",
        "outputId": "af2989c2-44a8-4170-fb62-68cec0a8cebb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "DAMAGE\n",
            "0    8516533\n",
            "1     120574\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "print(features_binary.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fTOzfKS3VKM",
        "outputId": "d9b41f7b-1dbd-4c64-e914-0b8a514a4a71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ORTPLZ  SUM_INSURED  CONSTRUCTION_YEAR    WFL  DRAIN_PIPE_INSURED  \\\n",
            "0  42109.0      71081.0        1967.565648   69.0                   0   \n",
            "1  42277.0      55708.0        1967.565648   65.0                   0   \n",
            "2  42389.0      74148.0        1967.565648   75.0                   0   \n",
            "4  42553.0      75682.0        1967.565648  119.0                   0   \n",
            "5  42113.0      70000.0        1967.565648  100.0                   0   \n",
            "\n",
            "   PRIOR_DAMAGES  UVV-KZ  DAMAGE  CORPORATE_DEVISION_VHV  \\\n",
            "0              0       1       0                    True   \n",
            "1              0       1       0                    True   \n",
            "2              0       1       0                    True   \n",
            "4              0       1       0                    True   \n",
            "5              0       1       0                    True   \n",
            "\n",
            "   CONSTRACTION_DESIGN_CARAVAN_MOTORHOME  ...  ZONE_4  ZONE_4.0  ZONE_5  \\\n",
            "0                                  False  ...   False     False   False   \n",
            "1                                  False  ...   False     False   False   \n",
            "2                                  False  ...   False     False   False   \n",
            "4                                  False  ...   False     False   False   \n",
            "5                                  False  ...   False     False   False   \n",
            "\n",
            "   ZONE_5.0  ZONE_6  ZONE_6.0  ZONE_7  ZONE_7.0  ZONE_8  ZONE_8.0  \n",
            "0     False   False     False   False     False   False     False  \n",
            "1     False   False     False   False     False   False     False  \n",
            "2     False   False     False   False     False   False     False  \n",
            "4     False   False     False   False     False   False     False  \n",
            "5     False   False     False   False     False   False     False  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "dmwwN1Fk9-mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split into test and training\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize RandomUnderSampler\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "g2tRFkvL99hn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Training the classifier\n",
        "rf_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Making probability predictions\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "EJMfXDqqAZOZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "\n",
        "# Converting probabilities to class predictions\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "# With undersampling accuracy gets worse, but we detect more TRUE Positives. Still way more false positive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vwjrTVhFXj",
        "outputId": "db2936ac-89c3-4d83-f1a2-9a17c0d2a03b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7853703379950007\n",
            "Confusion Matrix:\n",
            "[[1338839  364364]\n",
            " [   6392   17827]]\n",
            "True Positives: 17827\n",
            "False Positives: 364364\n",
            "True Negatives: 1338839\n",
            "False Negatives: 6392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88   1703203\n",
            "           1       0.05      0.74      0.09     24219\n",
            "\n",
            "    accuracy                           0.79   1727422\n",
            "   macro avg       0.52      0.76      0.48   1727422\n",
            "weighted avg       0.98      0.79      0.87   1727422\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature-importnace analysis\n",
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "# Display results\n",
        "print(\"Feature Importance:\")\n",
        "for i, feature in enumerate(X_train.columns):\n",
        "    print(f\"{feature}: {feature_importance[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTixu8nHavRD",
        "outputId": "d116c686-4fd8-4b73-a80e-63c4d49056e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "ORTPLZ: 0.22950934268938258\n",
            "SUM_INSURED: 0.3436387893280586\n",
            "CONSTRUCTION_YEAR: 0.10233732052560082\n",
            "WFL: 0.11902210383701167\n",
            "DRAIN_PIPE_INSURED: 0.0\n",
            "PRIOR_DAMAGES: 0.004227427149212484\n",
            "UVV-KZ: 0.014137294705900449\n",
            "CORPORATE_DEVISION_VHV: 0.1219592231461422\n",
            "CONSTRACTION_DESIGN_CARAVAN_MOTORHOME: 8.26432256751105e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_I: 0.00027824805381932284\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_II: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_III: 7.249581611118396e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_IV: 1.330879859145523e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_V: 2.0118167934125968e-07\n",
            "CONSTRACTION_DESIGN_NORMAL_VENTURE: 0.0010789227884194744\n",
            "CONSTRACTION_DESIGN_PREDOMINANTLY_WOODEN_ROOF: 0.00014440976673366968\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE: 0.0006388190920825517\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE_I: 0.0\n",
            "PRODUCTLINE_Kompakt: 0.0061697423506620365\n",
            "PRODUCTLINE_Plus: 0.001953922569924123\n",
            "PRODUCTLINE_Premium: 0.001659283059399923\n",
            "PRODUCTLINE_Sonst: 0.014688301109132768\n",
            "PRODUCTLINE_Top: 0.0034532815584079816\n",
            "UNDERWRITER_Y: 0.00526043325599241\n",
            "ZONE_1.0: 0.0024162436782179417\n",
            "ZONE_2.0: 0.0014661475168854295\n",
            "ZONE_3.0: 0.0013968164322887477\n",
            "ZONE_4.0: 0.0010030553762524442\n",
            "ZONE_5.0: 0.0006791113238424853\n",
            "ZONE_6.0: 0.00012018967707107168\n",
            "ZONE_7.0: 8.583349797855007e-05\n",
            "ZONE_8.0: 5.954968286178614e-05\n",
            "ZONE_0: 0.0007291135192884797\n",
            "ZONE_0.0: 3.965005856506764e-05\n",
            "ZONE_1: 0.006518653325393562\n",
            "ZONE_1.0: 0.00032333242775859044\n",
            "ZONE_2: 0.0022447366535717117\n",
            "ZONE_2.0: 0.0006406226005965495\n",
            "ZONE_3: 0.004975555266240754\n",
            "ZONE_3.0: 0.0006389249580279102\n",
            "ZONE_4: 0.003578866463324952\n",
            "ZONE_4.0: 0.0003907662936573053\n",
            "ZONE_5: 0.0017469485267464192\n",
            "ZONE_5.0: 0.00021870171941341975\n",
            "ZONE_6: 0.0002209353447939957\n",
            "ZONE_6.0: 9.800862116671537e-06\n",
            "ZONE_7: 0.00017161115981016917\n",
            "ZONE_7.0: 2.119429102096897e-05\n",
            "ZONE_8: 0.00012004779177105345\n",
            "ZONE_8.0: 9.68060090375542e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest with Rolling window"
      ],
      "metadata": {
        "id": "sXhtW_D_ljQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose variables where it makes logical including year column\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE', 'YEAR']]\n",
        "\n",
        "initial_features_clean = initial_features.dropna()"
      ],
      "metadata": {
        "id": "7mZ1DyNEoANN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pir7CO9ioRJd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "YEAR_INDEX = features_binary.columns.get_loc('YEAR')\n",
        "print(YEAR_INDEX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSk1hjJqoVi_",
        "outputId": "ab57990e-140a-4d2f-dcda-7733cdb20ef8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "shjdeTf2l191",
        "outputId": "32209bfe-169d-4dbd-8cc8-2d14b677572b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:15<02:15, 15.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    775271\n",
            "           1       0.39      0.29      0.33      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.69      0.64      0.66    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[770816   4455]\n",
            " [  6922   2814]]\n",
            "True Positives: 2814\n",
            "False Positives: 4455\n",
            "True Negatives: 770816\n",
            "False Negatives: 6922\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:30<02:04, 15.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.41      0.24      0.31     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.70      0.62      0.65    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[802460   3762]\n",
            " [  8175   2640]]\n",
            "True Positives: 2640\n",
            "False Positives: 3762\n",
            "True Negatives: 802460\n",
            "False Negatives: 8175\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:47<01:52, 16.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.43      0.23      0.30     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.71      0.62      0.65    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[758368   3301]\n",
            " [  8008   2451]]\n",
            "True Positives: 2451\n",
            "False Positives: 3301\n",
            "True Negatives: 758368\n",
            "False Negatives: 8008\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:02<01:34, 15.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.34      0.16      0.22     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.67      0.58      0.61    775789\n",
            "weighted avg       0.98      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[760835   3514]\n",
            " [  9594   1846]]\n",
            "True Positives: 1846\n",
            "False Positives: 3514\n",
            "True Negatives: 760835\n",
            "False Negatives: 9594\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:19<01:20, 16.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    771495\n",
            "           1       0.34      0.17      0.23     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.67      0.58      0.61    783975\n",
            "weighted avg       0.98      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767404   4091]\n",
            " [ 10334   2146]]\n",
            "True Positives: 2146\n",
            "False Positives: 4091\n",
            "True Negatives: 767404\n",
            "False Negatives: 10334\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:37<01:07, 16.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.33      0.17      0.23     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.66      0.58      0.61    794935\n",
            "weighted avg       0.97      0.98      0.98    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[775649   4910]\n",
            " [ 11919   2457]]\n",
            "True Positives: 2457\n",
            "False Positives: 4910\n",
            "True Negatives: 775649\n",
            "False Negatives: 11919\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:56<00:51, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.33      0.16      0.21     15770\n",
            "\n",
            "    accuracy                           0.98    803868\n",
            "   macro avg       0.65      0.58      0.60    803868\n",
            "weighted avg       0.97      0.98      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[782874   5224]\n",
            " [ 13250   2520]]\n",
            "True Positives: 2520\n",
            "False Positives: 5224\n",
            "True Negatives: 782874\n",
            "False Negatives: 13250\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:14<00:35, 17.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    797092\n",
            "           1       0.25      0.15      0.19     13298\n",
            "\n",
            "    accuracy                           0.98    810390\n",
            "   macro avg       0.62      0.57      0.59    810390\n",
            "weighted avg       0.97      0.98      0.98    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[791059   6033]\n",
            " [ 11238   2060]]\n",
            "True Positives: 2060\n",
            "False Positives: 6033\n",
            "True Negatives: 791059\n",
            "False Negatives: 11238\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:33<00:17, 17.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    800711\n",
            "           1       0.21      0.12      0.15     11149\n",
            "\n",
            "    accuracy                           0.98    811860\n",
            "   macro avg       0.60      0.56      0.57    811860\n",
            "weighted avg       0.98      0.98      0.98    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[795739   4972]\n",
            " [  9828   1321]]\n",
            "True Positives: 1321\n",
            "False Positives: 4972\n",
            "True Negatives: 795739\n",
            "False Negatives: 9828\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:50<00:00, 17.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    806672\n",
            "           1       0.04      0.11      0.06      2049\n",
            "\n",
            "    accuracy                           0.99    808721\n",
            "   macro avg       0.52      0.55      0.53    808721\n",
            "weighted avg       1.00      0.99      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[800957   5715]\n",
            " [  1826    223]]\n",
            "True Positives: 223\n",
            "False Positives: 5715\n",
            "True Negatives: 800957\n",
            "False Negatives: 1826\n",
            "Year: 2015, Recall Score: 0.2890304026294166\n",
            "Year: 2016, Recall Score: 0.24410540915395285\n",
            "Year: 2017, Recall Score: 0.23434362749784873\n",
            "Year: 2018, Recall Score: 0.16136363636363638\n",
            "Year: 2019, Recall Score: 0.1719551282051282\n",
            "Year: 2020, Recall Score: 0.17090984974958265\n",
            "Year: 2021, Recall Score: 0.15979708306911858\n",
            "Year: 2022, Recall Score: 0.15491051285907656\n",
            "Year: 2023, Recall Score: 0.11848596286662481\n",
            "Year: 2024, Recall Score: 0.10883357735480723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "WNPRV0LutSjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define initial features\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION', 'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL', 'ZONE', 'DRAIN_PIPE_INSURED', 'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'DAMAGE', 'YEAR']]\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "# Define feature and target\n",
        "columns_to_encode = ['CORPORATE_DEVISION', 'CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create binary variables using one-hot encoding\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate continuous and discrete features\n",
        "continuous_features = ['SUM_INSURED', 'CONSTRUCTION_YEAR']\n",
        "# The discrete features need to be adjusted after one-hot encoding\n",
        "discrete_features = list(set(X.columns) - set(continuous_features))"
      ],
      "metadata": {
        "id": "OXNnLuCbdc-T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "# Train GaussianNB on continuous features\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train[continuous_features], y_train)\n",
        "\n",
        "# Train MultinomialNB on discrete features\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train[discrete_features], y_train)\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTjSjOWoF5u",
        "outputId": "00a0427a-d56c-415e-f6f2-1944c48c5d11"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:03<00:27,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773616   1655]\n",
            " [  8536   1200]]\n",
            "True Positives: 1200\n",
            "False Positives: 1655\n",
            "True Negatives: 773616\n",
            "False Negatives: 8536\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:06<00:26,  3.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.48      0.11      0.18     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.74      0.55      0.59    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804964   1258]\n",
            " [  9640   1175]]\n",
            "True Positives: 1175\n",
            "False Positives: 1258\n",
            "True Negatives: 804964\n",
            "False Negatives: 9640\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:09<00:22,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.42      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760286   1383]\n",
            " [  9455   1004]]\n",
            "True Positives: 1004\n",
            "False Positives: 1383\n",
            "True Negatives: 760286\n",
            "False Negatives: 9455\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:12<00:18,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.16      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762597   1752]\n",
            " [ 11106    334]]\n",
            "True Positives: 334\n",
            "False Positives: 1752\n",
            "True Negatives: 762597\n",
            "False Negatives: 11106\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:15<00:15,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    771495\n",
            "           1       0.09      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.54      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.97    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767538   3957]\n",
            " [ 12103    377]]\n",
            "True Positives: 377\n",
            "False Positives: 3957\n",
            "True Negatives: 767538\n",
            "False Negatives: 12103\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:18<00:12,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.08      0.03      0.05     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.53      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[775127   5432]\n",
            " [ 13900    476]]\n",
            "True Positives: 476\n",
            "False Positives: 5432\n",
            "True Negatives: 775127\n",
            "False Negatives: 13900\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:21<00:09,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98    788098\n",
            "           1       0.05      0.04      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.52      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[777761  10337]\n",
            " [ 15188    582]]\n",
            "True Positives: 582\n",
            "False Positives: 10337\n",
            "True Negatives: 777761\n",
            "False Negatives: 15188\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:24<00:06,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    797092\n",
            "           1       0.04      0.05      0.05     13298\n",
            "\n",
            "    accuracy                           0.96    810390\n",
            "   macro avg       0.51      0.52      0.51    810390\n",
            "weighted avg       0.97      0.96      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[780519  16573]\n",
            " [ 12590    708]]\n",
            "True Positives: 708\n",
            "False Positives: 16573\n",
            "True Negatives: 780519\n",
            "False Negatives: 12590\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:27<00:03,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98    800711\n",
            "           1       0.04      0.07      0.05     11149\n",
            "\n",
            "    accuracy                           0.96    811860\n",
            "   macro avg       0.51      0.52      0.51    811860\n",
            "weighted avg       0.97      0.96      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[779298  21413]\n",
            " [ 10356    793]]\n",
            "True Positives: 793\n",
            "False Positives: 21413\n",
            "True Negatives: 779298\n",
            "False Negatives: 10356\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98    806672\n",
            "           1       0.01      0.08      0.01      2049\n",
            "\n",
            "    accuracy                           0.96    808721\n",
            "   macro avg       0.50      0.52      0.49    808721\n",
            "weighted avg       1.00      0.96      0.98    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[775821  30851]\n",
            " [  1877    172]]\n",
            "True Positives: 172\n",
            "False Positives: 30851\n",
            "True Negatives: 775821\n",
            "False Negatives: 1877\n",
            "Year: 2015, Recall Score: 0.12325390304026294\n",
            "Year: 2016, Recall Score: 0.10864539990753583\n",
            "Year: 2017, Recall Score: 0.09599388086815183\n",
            "Year: 2018, Recall Score: 0.029195804195804195\n",
            "Year: 2019, Recall Score: 0.030208333333333334\n",
            "Year: 2020, Recall Score: 0.03311074012242626\n",
            "Year: 2021, Recall Score: 0.03690551680405834\n",
            "Year: 2022, Recall Score: 0.0532410888855467\n",
            "Year: 2023, Recall Score: 0.07112745537716388\n",
            "Year: 2024, Recall Score: 0.08394338701805759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srilci2A3lB6",
        "outputId": "f29d891b-722e-43a1-aee2-71b87d0b067d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99   1719308\n",
            "           1       0.98      0.04      0.08     24428\n",
            "\n",
            "    accuracy                           0.99   1743736\n",
            "   macro avg       0.98      0.52      0.54   1743736\n",
            "weighted avg       0.99      0.99      0.98   1743736\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1719284      24]\n",
            " [  23369    1059]]\n",
            "True Positives: 1059\n",
            "False Positives: 24\n",
            "True Negatives: 1719284\n",
            "False Negatives: 23369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNjBsFwxmFB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}