{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miinsss/Capstone-Project/blob/main/Random_Forest_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bU5iM6J_2o"
      },
      "source": [
        "# Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ENHreirWKFF9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbf_dBkuKPCj"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LksDbqsQKVuC",
        "outputId": "852c5f1d-d26b-41da-b047-6e3502ed08e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-56a844a11275>:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  contract_class = pd.read_csv(contract_class_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ANO_SID CORPORATE_DEVISION   ORTPLZ  ORTS-NAME               STRASSE  \\\n",
            "0  4114028.0                VHV  42109.0  Wuppertal     Hans-BÃ¶ckler-Str.   \n",
            "1  4114039.0                VHV  42277.0  Wuppertal       Liegnitzer Str.   \n",
            "2  4114045.0                VHV  42389.0  Wuppertal             Rascheweg   \n",
            "3  4114049.0                VGV  42277.0  Wuppertal               Am Diek   \n",
            "4  4114055.0                VHV  42553.0    Velbert  Emil-Schniewind-Str.   \n",
            "\n",
            "   SUM_INSURED CONSTRACTION_DESIGN  CONSTRUCTION_YEAR        WFL ZONE  ...  \\\n",
            "0      71081.0      NORMAL_VENTURE        1967.565648   69.00000  2.0  ...   \n",
            "1      55708.0      NORMAL_VENTURE        1967.565648   65.00000  4.0  ...   \n",
            "2      74148.0      DESIGN_CLASS_I        1967.565648   75.00000  1.0  ...   \n",
            "3     664000.0      NORMAL_VENTURE        1967.565648  106.24368  NaN  ...   \n",
            "4      75682.0      NORMAL_VENTURE        1967.565648  119.00000  2.0  ...   \n",
            "\n",
            "   DRAIN_PIPE_INSURED  PRODUCTLINE  PRIOR_DAMAGES UVV-KZ  UNDERWRITER  \\\n",
            "0                   0        Sonst              0      1            Y   \n",
            "1                   0        Basis              0      1            Y   \n",
            "2                   0        Sonst              0      1            Y   \n",
            "3                   0      Kompakt              0      1            Y   \n",
            "4                   0        Sonst              0      1            Y   \n",
            "\n",
            "               PARTY-ID contract_year PIPE_PREMIUM_AMOUNT  YEAR  DAMAGE  \n",
            "0  N00WXYAWXFD704PT4712    2014-01-01             4.55070  2014       0  \n",
            "1  YH8XZ8AWXFD704PT4713    2014-01-01             4.54080  2014       0  \n",
            "2  AIPAVQEWXFD704PT4713    2014-01-01             3.18120  2014       0  \n",
            "3  GG0UA4KWXFD704PT4715    2014-01-01           154.60908  2014       0  \n",
            "4  P6XU2FAWXFD704PT4712    2014-01-01             5.89380  2014       0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the contract_classification.csv file\n",
        "contract_class_path = '/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/contract_classification.csv'\n",
        "contract_class = pd.read_csv(contract_class_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify content\n",
        "print(contract_class.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3k-fugN17z",
        "outputId": "9db5554b-219c-4688-d3aa-cd2bcba31c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "ANO_SID                     55\n",
            "CORPORATE_DEVISION           0\n",
            "ORTPLZ                  102482\n",
            "ORTS-NAME                 3901\n",
            "STRASSE                  16338\n",
            "SUM_INSURED              16503\n",
            "CONSTRACTION_DESIGN    1188450\n",
            "CONSTRUCTION_YEAR            0\n",
            "WFL                      16670\n",
            "ZONE                    988470\n",
            "SF-SYSTEM              9717058\n",
            "TYPE_OF_DEDUCTIBLE           0\n",
            "DRAIN_PIPE_INSURED           0\n",
            "PRODUCTLINE            1735746\n",
            "PRIOR_DAMAGES                0\n",
            "UVV-KZ                       0\n",
            "UNDERWRITER                  0\n",
            "PARTY-ID                   203\n",
            "contract_year                0\n",
            "PIPE_PREMIUM_AMOUNT        167\n",
            "YEAR                         0\n",
            "DAMAGE                       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(contract_class['DAMAGE'].value_counts())\n",
        "\n",
        "\n",
        "na_counts = contract_class.isna().sum()\n",
        "\n",
        "print(na_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoya1IqoQlP9"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKlJomDBmkF0"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWuhhszlQyyR",
        "outputId": "d691d35e-f258-4489-fed7-18326c6c0ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    11389665\n",
            "1      184774\n",
            "Name: count, dtype: int64\n",
            "DAMAGE\n",
            "0    8516533\n",
            "1     120574\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Choose variables where it makes logical sense\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE']]\n",
        "\n",
        "print(initial_features['DAMAGE'].value_counts())\n",
        "\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "print(initial_features_clean['DAMAGE'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fTOzfKS3VKM",
        "outputId": "5241dd56-b5da-468c-9e31-6443e4f8922f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ORTPLZ  SUM_INSURED  CONSTRUCTION_YEAR    WFL  DRAIN_PIPE_INSURED  \\\n",
            "0  42109.0      71081.0        1967.565648   69.0                   0   \n",
            "1  42277.0      55708.0        1967.565648   65.0                   0   \n",
            "2  42389.0      74148.0        1967.565648   75.0                   0   \n",
            "4  42553.0      75682.0        1967.565648  119.0                   0   \n",
            "5  42113.0      70000.0        1967.565648  100.0                   0   \n",
            "\n",
            "   PRIOR_DAMAGES  UVV-KZ  DAMAGE  CORPORATE_DEVISION_VHV  \\\n",
            "0              0       1       0                    True   \n",
            "1              0       1       0                    True   \n",
            "2              0       1       0                    True   \n",
            "4              0       1       0                    True   \n",
            "5              0       1       0                    True   \n",
            "\n",
            "   CONSTRACTION_DESIGN_CARAVAN_MOTORHOME  ...  ZONE_4  ZONE_4.0  ZONE_5  \\\n",
            "0                                  False  ...   False     False   False   \n",
            "1                                  False  ...   False     False   False   \n",
            "2                                  False  ...   False     False   False   \n",
            "4                                  False  ...   False     False   False   \n",
            "5                                  False  ...   False     False   False   \n",
            "\n",
            "   ZONE_5.0  ZONE_6  ZONE_6.0  ZONE_7  ZONE_7.0  ZONE_8  ZONE_8.0  \n",
            "0     False   False     False   False     False   False     False  \n",
            "1     False   False     False   False     False   False     False  \n",
            "2     False   False     False   False     False   False     False  \n",
            "4     False   False     False   False     False   False     False  \n",
            "5     False   False     False   False     False   False     False  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "print(features_binary.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwwN1Fk9-mx"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2tRFkvL99hn"
      },
      "outputs": [],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split into test and training\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize RandomUnderSampler\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJMfXDqqAZOZ"
      },
      "outputs": [],
      "source": [
        "# Initializing Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Training the classifier\n",
        "rf_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Making probability predictions\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vwjrTVhFXj",
        "outputId": "db2936ac-89c3-4d83-f1a2-9a17c0d2a03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7853703379950007\n",
            "Confusion Matrix:\n",
            "[[1338839  364364]\n",
            " [   6392   17827]]\n",
            "True Positives: 17827\n",
            "False Positives: 364364\n",
            "True Negatives: 1338839\n",
            "False Negatives: 6392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88   1703203\n",
            "           1       0.05      0.74      0.09     24219\n",
            "\n",
            "    accuracy                           0.79   1727422\n",
            "   macro avg       0.52      0.76      0.48   1727422\n",
            "weighted avg       0.98      0.79      0.87   1727422\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "\n",
        "# Converting probabilities to class predictions\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "# With undersampling accuracy gets worse, but we detect more TRUE Positives. Still way more false positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTixu8nHavRD",
        "outputId": "d116c686-4fd8-4b73-a80e-63c4d49056e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Importance:\n",
            "ORTPLZ: 0.22950934268938258\n",
            "SUM_INSURED: 0.3436387893280586\n",
            "CONSTRUCTION_YEAR: 0.10233732052560082\n",
            "WFL: 0.11902210383701167\n",
            "DRAIN_PIPE_INSURED: 0.0\n",
            "PRIOR_DAMAGES: 0.004227427149212484\n",
            "UVV-KZ: 0.014137294705900449\n",
            "CORPORATE_DEVISION_VHV: 0.1219592231461422\n",
            "CONSTRACTION_DESIGN_CARAVAN_MOTORHOME: 8.26432256751105e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_I: 0.00027824805381932284\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_II: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_III: 7.249581611118396e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_IV: 1.330879859145523e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_V: 2.0118167934125968e-07\n",
            "CONSTRACTION_DESIGN_NORMAL_VENTURE: 0.0010789227884194744\n",
            "CONSTRACTION_DESIGN_PREDOMINANTLY_WOODEN_ROOF: 0.00014440976673366968\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE: 0.0006388190920825517\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE_I: 0.0\n",
            "PRODUCTLINE_Kompakt: 0.0061697423506620365\n",
            "PRODUCTLINE_Plus: 0.001953922569924123\n",
            "PRODUCTLINE_Premium: 0.001659283059399923\n",
            "PRODUCTLINE_Sonst: 0.014688301109132768\n",
            "PRODUCTLINE_Top: 0.0034532815584079816\n",
            "UNDERWRITER_Y: 0.00526043325599241\n",
            "ZONE_1.0: 0.0024162436782179417\n",
            "ZONE_2.0: 0.0014661475168854295\n",
            "ZONE_3.0: 0.0013968164322887477\n",
            "ZONE_4.0: 0.0010030553762524442\n",
            "ZONE_5.0: 0.0006791113238424853\n",
            "ZONE_6.0: 0.00012018967707107168\n",
            "ZONE_7.0: 8.583349797855007e-05\n",
            "ZONE_8.0: 5.954968286178614e-05\n",
            "ZONE_0: 0.0007291135192884797\n",
            "ZONE_0.0: 3.965005856506764e-05\n",
            "ZONE_1: 0.006518653325393562\n",
            "ZONE_1.0: 0.00032333242775859044\n",
            "ZONE_2: 0.0022447366535717117\n",
            "ZONE_2.0: 0.0006406226005965495\n",
            "ZONE_3: 0.004975555266240754\n",
            "ZONE_3.0: 0.0006389249580279102\n",
            "ZONE_4: 0.003578866463324952\n",
            "ZONE_4.0: 0.0003907662936573053\n",
            "ZONE_5: 0.0017469485267464192\n",
            "ZONE_5.0: 0.00021870171941341975\n",
            "ZONE_6: 0.0002209353447939957\n",
            "ZONE_6.0: 9.800862116671537e-06\n",
            "ZONE_7: 0.00017161115981016917\n",
            "ZONE_7.0: 2.119429102096897e-05\n",
            "ZONE_8: 0.00012004779177105345\n",
            "ZONE_8.0: 9.68060090375542e-06\n"
          ]
        }
      ],
      "source": [
        "# Feature-importnace analysis\n",
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "# Display results\n",
        "print(\"Feature Importance:\")\n",
        "for i, feature in enumerate(X_train.columns):\n",
        "    print(f\"{feature}: {feature_importance[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhtW_D_ljQv"
      },
      "source": [
        "## Random Forest with Rolling window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7mZ1DyNEoANN"
      },
      "outputs": [],
      "source": [
        "#Choose variables where it makes logical including year column\n",
        "\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION','ORTPLZ',  'SUM_INSURED', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED','PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE', 'YEAR']]\n",
        "\n",
        "initial_features_clean = initial_features.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "pir7CO9ioRJd"
      },
      "outputs": [],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSk1hjJqoVi_",
        "outputId": "daeb631f-ddc9-41e5-ff32-8dadc94eb664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "YEAR_INDEX = features_binary.columns.get_loc('YEAR')\n",
        "print(YEAR_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shjdeTf2l191",
        "outputId": "f3338e5b-30f7-4f0a-d2c1-910cef84f464"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|â         | 1/10 [01:08<10:20, 68.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.46      0.28      0.35      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.73      0.64      0.67    785007\n",
            "weighted avg       0.98      0.99      0.99    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[772052   3219]\n",
            " [  6993   2743]]\n",
            "True Positives: 2743\n",
            "False Positives: 3219\n",
            "True Negatives: 772052\n",
            "False Negatives: 6993\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|ââ        | 2/10 [02:21<09:30, 71.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.46      0.24      0.32     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.73      0.62      0.65    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[803211   3011]\n",
            " [  8219   2596]]\n",
            "True Positives: 2596\n",
            "False Positives: 3011\n",
            "True Negatives: 803211\n",
            "False Negatives: 8219\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|âââ       | 3/10 [03:35<08:27, 72.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.48      0.23      0.31     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.74      0.61      0.65    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[759057   2612]\n",
            " [  8032   2427]]\n",
            "True Positives: 2427\n",
            "False Positives: 2612\n",
            "True Negatives: 759057\n",
            "False Negatives: 8032\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|ââââ      | 4/10 [04:44<07:05, 70.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.39      0.15      0.22     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.69      0.58      0.61    775789\n",
            "weighted avg       0.98      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[761545   2804]\n",
            " [  9682   1758]]\n",
            "True Positives: 1758\n",
            "False Positives: 2804\n",
            "True Negatives: 761545\n",
            "False Negatives: 9682\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|âââââ     | 5/10 [05:58<05:59, 71.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    771495\n",
            "           1       0.39      0.17      0.23     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.69      0.58      0.61    783975\n",
            "weighted avg       0.98      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[768278   3217]\n",
            " [ 10412   2068]]\n",
            "True Positives: 2068\n",
            "False Positives: 3217\n",
            "True Negatives: 768278\n",
            "False Negatives: 10412\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|ââââââ    | 6/10 [07:17<04:57, 74.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    780559\n",
            "           1       0.39      0.16      0.23     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.69      0.58      0.61    794935\n",
            "weighted avg       0.97      0.98      0.98    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[776952   3607]\n",
            " [ 12049   2327]]\n",
            "True Positives: 2327\n",
            "False Positives: 3607\n",
            "True Negatives: 776952\n",
            "False Negatives: 12049\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|âââââââ   | 7/10 [08:40<03:51, 77.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.37      0.15      0.21     15770\n",
            "\n",
            "    accuracy                           0.98    803868\n",
            "   macro avg       0.68      0.57      0.60    803868\n",
            "weighted avg       0.97      0.98      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[784070   4028]\n",
            " [ 13386   2384]]\n",
            "True Positives: 2384\n",
            "False Positives: 4028\n",
            "True Negatives: 784070\n",
            "False Negatives: 13386\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|ââââââââ  | 8/10 [10:02<02:37, 78.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    797092\n",
            "           1       0.30      0.14      0.19     13298\n",
            "\n",
            "    accuracy                           0.98    810390\n",
            "   macro avg       0.64      0.57      0.59    810390\n",
            "weighted avg       0.97      0.98      0.98    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[792603   4489]\n",
            " [ 11415   1883]]\n",
            "True Positives: 1883\n",
            "False Positives: 4489\n",
            "True Negatives: 792603\n",
            "False Negatives: 11415\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|âââââââââ | 9/10 [11:25<01:20, 80.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    800711\n",
            "           1       0.26      0.11      0.15     11149\n",
            "\n",
            "    accuracy                           0.98    811860\n",
            "   macro avg       0.62      0.55      0.57    811860\n",
            "weighted avg       0.98      0.98      0.98    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[797130   3581]\n",
            " [  9921   1228]]\n",
            "True Positives: 1228\n",
            "False Positives: 3581\n",
            "True Negatives: 797130\n",
            "False Negatives: 9921\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 10/10 [12:46<00:00, 76.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    806672\n",
            "           1       0.04      0.10      0.06      2049\n",
            "\n",
            "    accuracy                           0.99    808721\n",
            "   macro avg       0.52      0.55      0.53    808721\n",
            "weighted avg       1.00      0.99      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[801513   5159]\n",
            " [  1841    208]]\n",
            "True Positives: 208\n",
            "False Positives: 5159\n",
            "True Negatives: 801513\n",
            "False Negatives: 1841\n",
            "Year: 2015, Recall Score: 0.2817378800328677\n",
            "Year: 2016, Recall Score: 0.24003698566805362\n",
            "Year: 2017, Recall Score: 0.23204895305478535\n",
            "Year: 2018, Recall Score: 0.15367132867132868\n",
            "Year: 2019, Recall Score: 0.1657051282051282\n",
            "Year: 2020, Recall Score: 0.16186700055648304\n",
            "Year: 2021, Recall Score: 0.1511731135066582\n",
            "Year: 2022, Recall Score: 0.1416002406376899\n",
            "Year: 2023, Recall Score: 0.11014440757018566\n",
            "Year: 2024, Recall Score: 0.10151293313811616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTsXs3AgLwAE"
      },
      "source": [
        "## Random Forrest with expanding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZqoHusLLqif",
        "outputId": "ed9e0606-c9c0-4c68-f7d5-d69cef5909ed"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2015: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 10}\n",
            "Classification report for year 2015:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|â         | 1/10 [07:04<1:03:38, 424.32s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    768070\n",
            "           1       0.91      0.22      0.35      9606\n",
            "\n",
            "    accuracy                           0.99    777676\n",
            "   macro avg       0.95      0.61      0.67    777676\n",
            "weighted avg       0.99      0.99      0.99    777676\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[767850    220]\n",
            " [  7489   2117]]\n",
            "True Positives: 2117\n",
            "False Positives: 220\n",
            "True Negatives: 767850\n",
            "False Negatives: 7489\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for year 2016: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|ââ        | 2/10 [24:44<1:46:28, 798.53s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    797816\n",
            "           1       0.85      0.21      0.33     10694\n",
            "\n",
            "    accuracy                           0.99    808510\n",
            "   macro avg       0.92      0.60      0.66    808510\n",
            "weighted avg       0.99      0.99      0.99    808510\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[797431    385]\n",
            " [  8475   2219]]\n",
            "True Positives: 2219\n",
            "False Positives: 385\n",
            "True Negatives: 797431\n",
            "False Negatives: 8475\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2017: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 10}\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|âââ       | 3/10 [51:08<2:14:58, 1156.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    754974\n",
            "           1       0.93      0.19      0.32     10393\n",
            "\n",
            "    accuracy                           0.99    765367\n",
            "   macro avg       0.96      0.60      0.66    765367\n",
            "weighted avg       0.99      0.99      0.99    765367\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[754826    148]\n",
            " [  8403   1990]]\n",
            "True Positives: 1990\n",
            "False Positives: 148\n",
            "True Negatives: 754826\n",
            "False Negatives: 8403\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for year 2018: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|ââââ      | 4/10 [1:26:39<2:34:08, 1541.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    756661\n",
            "           1       0.82      0.13      0.23     11321\n",
            "\n",
            "    accuracy                           0.99    767982\n",
            "   macro avg       0.90      0.57      0.61    767982\n",
            "weighted avg       0.98      0.99      0.98    767982\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[756337    324]\n",
            " [  9841   1480]]\n",
            "True Positives: 1480\n",
            "False Positives: 324\n",
            "True Negatives: 756337\n",
            "False Negatives: 9841\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2019: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|âââââ     | 5/10 [2:14:33<2:48:30, 2022.10s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    762788\n",
            "           1       0.63      0.15      0.25     12360\n",
            "\n",
            "    accuracy                           0.99    775148\n",
            "   macro avg       0.81      0.58      0.62    775148\n",
            "weighted avg       0.98      0.99      0.98    775148\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[761691   1097]\n",
            " [ 10458   1902]]\n",
            "True Positives: 1902\n",
            "False Positives: 1097\n",
            "True Negatives: 761691\n",
            "False Negatives: 10458\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2020: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|ââââââ    | 6/10 [3:18:39<2:56:08, 2642.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    773937\n",
            "           1       0.76      0.14      0.24     14300\n",
            "\n",
            "    accuracy                           0.98    788237\n",
            "   macro avg       0.87      0.57      0.62    788237\n",
            "weighted avg       0.98      0.98      0.98    788237\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[773275    662]\n",
            " [ 12241   2059]]\n",
            "True Positives: 2059\n",
            "False Positives: 662\n",
            "True Negatives: 773275\n",
            "False Negatives: 12241\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2021: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 10}\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|âââââââ   | 7/10 [4:38:11<2:46:55, 3338.50s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    780481\n",
            "           1       0.77      0.12      0.21     15702\n",
            "\n",
            "    accuracy                           0.98    796183\n",
            "   macro avg       0.88      0.56      0.60    796183\n",
            "weighted avg       0.98      0.98      0.98    796183\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[779909    572]\n",
            " [ 13754   1948]]\n",
            "True Positives: 1948\n",
            "False Positives: 572\n",
            "True Negatives: 779909\n",
            "False Negatives: 13754\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2022: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|ââââââââ  | 8/10 [6:13:12<2:16:21, 4090.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    791578\n",
            "           1       0.71      0.12      0.21     13219\n",
            "\n",
            "    accuracy                           0.98    804797\n",
            "   macro avg       0.85      0.56      0.60    804797\n",
            "weighted avg       0.98      0.98      0.98    804797\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[790914    664]\n",
            " [ 11596   1623]]\n",
            "True Positives: 1623\n",
            "False Positives: 664\n",
            "True Negatives: 790914\n",
            "False Negatives: 11596\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2023: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 20}\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|âââââââââ | 9/10 [8:06:04<1:22:08, 4928.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    794432\n",
            "           1       0.72      0.10      0.17     11113\n",
            "\n",
            "    accuracy                           0.99    805545\n",
            "   macro avg       0.85      0.55      0.58    805545\n",
            "weighted avg       0.98      0.99      0.98    805545\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[794003    429]\n",
            " [ 10016   1097]]\n",
            "True Positives: 1097\n",
            "False Positives: 429\n",
            "True Negatives: 794003\n",
            "False Negatives: 10016\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for year 2024: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 10/10 [10:06:31<00:00, 3639.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    799514\n",
            "           1       0.14      0.09      0.11      2048\n",
            "\n",
            "    accuracy                           1.00    801562\n",
            "   macro avg       0.57      0.54      0.55    801562\n",
            "weighted avg       1.00      1.00      1.00    801562\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[798377   1137]\n",
            " [  1868    180]]\n",
            "True Positives: 180\n",
            "False Positives: 1137\n",
            "True Negatives: 798377\n",
            "False Negatives: 1868\n",
            "Year: 2015, Recall Score: 0.22038309389964605\n",
            "Year: 2016, Recall Score: 0.20749953244810174\n",
            "Year: 2017, Recall Score: 0.1914750312710478\n",
            "Year: 2018, Recall Score: 0.13073050083914847\n",
            "Year: 2019, Recall Score: 0.15388349514563107\n",
            "Year: 2020, Recall Score: 0.143986013986014\n",
            "Year: 2021, Recall Score: 0.12406062921920774\n",
            "Year: 2022, Recall Score: 0.12277781980482638\n",
            "Year: 2023, Recall Score: 0.09871321875281203\n",
            "Year: 2024, Recall Score: 0.087890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 20],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(1, len(years))):\n",
        "    test_year = years[i]\n",
        "    train_years = years[:i]  # All years up to the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'].isin(train_years)]\n",
        "    y_train = y[features_binary['YEAR'].isin(train_years)]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize the Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Perform Grid Search with cross-validation\n",
        "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid,\n",
        "                               cv=3, n_jobs=-1, verbose=2, scoring='recall')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model from Grid Search\n",
        "    best_rf_classifier = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = best_rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the best parameters for the current year\n",
        "    print(f\"Best parameters for year {test_year}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities_last_year = y_prob\n",
        "\n",
        "# Convert the probabilities to a DataFrame\n",
        "probabilities_df = pd.DataFrame(probabilities_last_year, columns=['Probability'])\n",
        "\n",
        "# Save to a CSV file\n",
        "probabilities_df.to_csv('probabilities_last_year.csv', index=False)\n",
        "\n",
        "# Count the number of probabilities greater than 1\n",
        "count_greater_than_one = (probabilities_last_year > 1).sum()\n",
        "\n",
        "# Print the count\n",
        "print(f\"Number of entries in the probability array greater than 1: {count_greater_than_one}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWhEv4t4b5Db",
        "outputId": "62799d26-dcd4-48c4-9fa3-78bd8606f801"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in the probability array greater than 1: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNPRV0LutSjd"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OXNnLuCbdc-T"
      },
      "outputs": [],
      "source": [
        "# Define initial features\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION', 'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL', 'ZONE', 'DRAIN_PIPE_INSURED', 'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'DAMAGE', 'YEAR']]\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "# Define feature and target\n",
        "columns_to_encode = ['CORPORATE_DEVISION', 'CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create binary variables using one-hot encoding\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate continuous and discrete features\n",
        "continuous_features = ['SUM_INSURED', 'CONSTRUCTION_YEAR']\n",
        "# The discrete features need to be adjusted after one-hot encoding\n",
        "discrete_features = list(set(X.columns) - set(continuous_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTjSjOWoF5u",
        "outputId": "00a0427a-d56c-415e-f6f2-1944c48c5d11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|â         | 1/10 [00:03<00:27,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773616   1655]\n",
            " [  8536   1200]]\n",
            "True Positives: 1200\n",
            "False Positives: 1655\n",
            "True Negatives: 773616\n",
            "False Negatives: 8536\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|ââ        | 2/10 [00:06<00:26,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.48      0.11      0.18     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.74      0.55      0.59    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804964   1258]\n",
            " [  9640   1175]]\n",
            "True Positives: 1175\n",
            "False Positives: 1258\n",
            "True Negatives: 804964\n",
            "False Negatives: 9640\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|âââ       | 3/10 [00:09<00:22,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.42      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760286   1383]\n",
            " [  9455   1004]]\n",
            "True Positives: 1004\n",
            "False Positives: 1383\n",
            "True Negatives: 760286\n",
            "False Negatives: 9455\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|ââââ      | 4/10 [00:12<00:18,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.16      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762597   1752]\n",
            " [ 11106    334]]\n",
            "True Positives: 334\n",
            "False Positives: 1752\n",
            "True Negatives: 762597\n",
            "False Negatives: 11106\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|âââââ     | 5/10 [00:15<00:15,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    771495\n",
            "           1       0.09      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.54      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.97    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767538   3957]\n",
            " [ 12103    377]]\n",
            "True Positives: 377\n",
            "False Positives: 3957\n",
            "True Negatives: 767538\n",
            "False Negatives: 12103\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|ââââââ    | 6/10 [00:18<00:12,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.08      0.03      0.05     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.53      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[775127   5432]\n",
            " [ 13900    476]]\n",
            "True Positives: 476\n",
            "False Positives: 5432\n",
            "True Negatives: 775127\n",
            "False Negatives: 13900\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|âââââââ   | 7/10 [00:21<00:09,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98    788098\n",
            "           1       0.05      0.04      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.52      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[777761  10337]\n",
            " [ 15188    582]]\n",
            "True Positives: 582\n",
            "False Positives: 10337\n",
            "True Negatives: 777761\n",
            "False Negatives: 15188\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|ââââââââ  | 8/10 [00:24<00:06,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    797092\n",
            "           1       0.04      0.05      0.05     13298\n",
            "\n",
            "    accuracy                           0.96    810390\n",
            "   macro avg       0.51      0.52      0.51    810390\n",
            "weighted avg       0.97      0.96      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[780519  16573]\n",
            " [ 12590    708]]\n",
            "True Positives: 708\n",
            "False Positives: 16573\n",
            "True Negatives: 780519\n",
            "False Negatives: 12590\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|âââââââââ | 9/10 [00:27<00:03,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98    800711\n",
            "           1       0.04      0.07      0.05     11149\n",
            "\n",
            "    accuracy                           0.96    811860\n",
            "   macro avg       0.51      0.52      0.51    811860\n",
            "weighted avg       0.97      0.96      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[779298  21413]\n",
            " [ 10356    793]]\n",
            "True Positives: 793\n",
            "False Positives: 21413\n",
            "True Negatives: 779298\n",
            "False Negatives: 10356\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 10/10 [00:30<00:00,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98    806672\n",
            "           1       0.01      0.08      0.01      2049\n",
            "\n",
            "    accuracy                           0.96    808721\n",
            "   macro avg       0.50      0.52      0.49    808721\n",
            "weighted avg       1.00      0.96      0.98    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[775821  30851]\n",
            " [  1877    172]]\n",
            "True Positives: 172\n",
            "False Positives: 30851\n",
            "True Negatives: 775821\n",
            "False Negatives: 1877\n",
            "Year: 2015, Recall Score: 0.12325390304026294\n",
            "Year: 2016, Recall Score: 0.10864539990753583\n",
            "Year: 2017, Recall Score: 0.09599388086815183\n",
            "Year: 2018, Recall Score: 0.029195804195804195\n",
            "Year: 2019, Recall Score: 0.030208333333333334\n",
            "Year: 2020, Recall Score: 0.03311074012242626\n",
            "Year: 2021, Recall Score: 0.03690551680405834\n",
            "Year: 2022, Recall Score: 0.0532410888855467\n",
            "Year: 2023, Recall Score: 0.07112745537716388\n",
            "Year: 2024, Recall Score: 0.08394338701805759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "# Train GaussianNB on continuous features\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train[continuous_features], y_train)\n",
        "\n",
        "# Train MultinomialNB on discrete features\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train[discrete_features], y_train)\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEXUyHcDbQtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srilci2A3lB6",
        "outputId": "f29d891b-722e-43a1-aee2-71b87d0b067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99   1719308\n",
            "           1       0.98      0.04      0.08     24428\n",
            "\n",
            "    accuracy                           0.99   1743736\n",
            "   macro avg       0.98      0.52      0.54   1743736\n",
            "weighted avg       0.99      0.99      0.98   1743736\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1719284      24]\n",
            " [  23369    1059]]\n",
            "True Positives: 1059\n",
            "False Positives: 24\n",
            "True Negatives: 1719284\n",
            "False Negatives: 23369\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes with expanding window"
      ],
      "metadata": {
        "id": "e-6EMCOreuRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yNjBsFwxmFB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7148187a-fc8c-4935-94ae-90a9e6bd3fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for GaussianNB in year 2015: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2015: {'alpha': 0.1}\n",
            "Classification report for year 2015:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|â         | 1/10 [00:08<01:17,  8.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773620   1651]\n",
            " [  8539   1197]]\n",
            "True Positives: 1197\n",
            "False Positives: 1651\n",
            "True Negatives: 773620\n",
            "False Negatives: 8539\n",
            "Best parameters for GaussianNB in year 2016: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2016: {'alpha': 2.0}\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|ââ        | 2/10 [00:18<01:15,  9.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.43      0.11      0.17     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.71      0.55      0.58    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804652   1570]\n",
            " [  9634   1181]]\n",
            "True Positives: 1181\n",
            "False Positives: 1570\n",
            "True Negatives: 804652\n",
            "False Negatives: 9634\n",
            "Best parameters for GaussianNB in year 2017: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2017: {'alpha': 2.0}\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|âââ       | 3/10 [00:31<01:17, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.40      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760187   1482]\n",
            " [  9453   1006]]\n",
            "True Positives: 1006\n",
            "False Positives: 1482\n",
            "True Negatives: 760187\n",
            "False Negatives: 9453\n",
            "Best parameters for GaussianNB in year 2018: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2018: {'alpha': 0.1}\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|ââââ      | 4/10 [00:48<01:20, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.15      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762467   1882]\n",
            " [ 11105    335]]\n",
            "True Positives: 335\n",
            "False Positives: 1882\n",
            "True Negatives: 762467\n",
            "False Negatives: 11105\n",
            "Best parameters for GaussianNB in year 2019: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2019: {'alpha': 0.1}\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|âââââ     | 5/10 [01:08<01:19, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    771495\n",
            "           1       0.12      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.55      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[769127   2368]\n",
            " [ 12146    334]]\n",
            "True Positives: 334\n",
            "False Positives: 2368\n",
            "True Negatives: 769127\n",
            "False Negatives: 12146\n",
            "Best parameters for GaussianNB in year 2020: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2020: {'alpha': 0.1}\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|ââââââ    | 6/10 [01:32<01:13, 18.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    780559\n",
            "           1       0.11      0.03      0.04     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.54      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[777226   3333]\n",
            " [ 13976    400]]\n",
            "True Positives: 400\n",
            "False Positives: 3333\n",
            "True Negatives: 777226\n",
            "False Negatives: 13976\n",
            "Best parameters for GaussianNB in year 2021: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2021: {'alpha': 0.5}\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|âââââââ   | 7/10 [01:59<01:03, 21.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.07      0.03      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.53      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[782902   5196]\n",
            " [ 15360    410]]\n",
            "True Positives: 410\n",
            "False Positives: 5196\n",
            "True Negatives: 782902\n",
            "False Negatives: 15360\n",
            "Best parameters for GaussianNB in year 2022: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2022: {'alpha': 0.1}\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|ââââââââ  | 8/10 [02:30<00:49, 24.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    797092\n",
            "           1       0.06      0.04      0.05     13298\n",
            "\n",
            "    accuracy                           0.97    810390\n",
            "   macro avg       0.52      0.51      0.52    810390\n",
            "weighted avg       0.97      0.97      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[789534   7558]\n",
            " [ 12814    484]]\n",
            "True Positives: 484\n",
            "False Positives: 7558\n",
            "True Negatives: 789534\n",
            "False Negatives: 12814\n",
            "Best parameters for GaussianNB in year 2023: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2023: {'alpha': 0.1}\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|âââââââââ | 9/10 [03:07<00:28, 28.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    800711\n",
            "           1       0.05      0.05      0.05     11149\n",
            "\n",
            "    accuracy                           0.97    811860\n",
            "   macro avg       0.52      0.52      0.52    811860\n",
            "weighted avg       0.97      0.97      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[790632  10079]\n",
            " [ 10566    583]]\n",
            "True Positives: 583\n",
            "False Positives: 10079\n",
            "True Negatives: 790632\n",
            "False Negatives: 10566\n",
            "Best parameters for GaussianNB in year 2024: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2024: {'alpha': 0.1}\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 10/10 [03:48<00:00, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99    806672\n",
            "           1       0.01      0.05      0.01      2049\n",
            "\n",
            "    accuracy                           0.98    808721\n",
            "   macro avg       0.50      0.52      0.50    808721\n",
            "weighted avg       1.00      0.98      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[793852  12820]\n",
            " [  1944    105]]\n",
            "True Positives: 105\n",
            "False Positives: 12820\n",
            "True Negatives: 793852\n",
            "False Negatives: 1944\n",
            "Year: 2015, Recall Score: 0.12294576828266228\n",
            "Year: 2016, Recall Score: 0.10920018492834027\n",
            "Year: 2017, Recall Score: 0.09618510373840711\n",
            "Year: 2018, Recall Score: 0.029283216783216784\n",
            "Year: 2019, Recall Score: 0.02676282051282051\n",
            "Year: 2020, Recall Score: 0.027824151363383415\n",
            "Year: 2021, Recall Score: 0.02599873176918199\n",
            "Year: 2022, Recall Score: 0.036396450594074294\n",
            "Year: 2023, Recall Score: 0.052291685352946454\n",
            "Year: 2024, Recall Score: 0.05124450951683748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define parameter grids for GaussianNB and MultinomialNB\n",
        "gnb_param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
        "}\n",
        "\n",
        "mnb_param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(1, len(years))):\n",
        "    test_year = years[i]\n",
        "    train_years = years[:i]  # All years up to the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'].isin(train_years)]\n",
        "    y_train = y[features_binary['YEAR'].isin(train_years)]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize GaussianNB and perform Grid Search\n",
        "    gnb = GaussianNB()\n",
        "    gnb_grid_search = GridSearchCV(estimator=gnb, param_grid=gnb_param_grid, cv=3, n_jobs=-1, scoring='recall')\n",
        "    gnb_grid_search.fit(X_train[continuous_features], y_train)\n",
        "    best_gnb = gnb_grid_search.best_estimator_\n",
        "\n",
        "    # Initialize MultinomialNB and perform Grid Search\n",
        "    mnb = MultinomialNB()\n",
        "    mnb_grid_search = GridSearchCV(estimator=mnb, param_grid=mnb_param_grid, cv=3, n_jobs=-1, scoring='recall')\n",
        "    mnb_grid_search.fit(X_train[discrete_features], y_train)\n",
        "    best_mnb = mnb_grid_search.best_estimator_\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = best_gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = best_mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the best parameters for the current year\n",
        "    print(f\"Best parameters for GaussianNB in year {test_year}: {gnb_grid_search.best_params_}\")\n",
        "    print(f\"Best parameters for MultinomialNB in year {test_year}: {mnb_grid_search.best_params_}\")\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOiObFuWuDCKt57dmiUJHci",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}