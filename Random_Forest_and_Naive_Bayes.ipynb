{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miinsss/Capstone-Project/blob/main/Random_Forest_and_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bU5iM6J_2o"
      },
      "source": [
        "# Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ENHreirWKFF9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbf_dBkuKPCj"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LksDbqsQKVuC",
        "outputId": "5d631500-84a3-4896-d02d-b170c8a014b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the contract_classification.csv file\n",
        "contract_class_path = '/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/contracts_with_new_data_MEAN.csv'\n",
        "contract_class = pd.read_csv(contract_class_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify content\n",
        "print(contract_class.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhO042Kw5kQJ",
        "outputId": "c6361b7d-3b6e-42ed-90fb-85a9243661fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-283dbef524b6>:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  contract_class = pd.read_csv(contract_class_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0    ANO_SID CORPORATE_DEVISION  ORTPLZ  ORTS-NAME  \\\n",
            "0           0  4114028.0                VHV   42109  Wuppertal   \n",
            "1           1  4114039.0                VHV   42277  Wuppertal   \n",
            "2           2  4114045.0                VHV   42389  Wuppertal   \n",
            "3           3  4114049.0                VGV   42277  Wuppertal   \n",
            "4           4  4114055.0                VHV   42553    Velbert   \n",
            "\n",
            "                STRASSE  SUM_INSURED CONSTRACTION_DESIGN  CONSTRUCTION_YEAR  \\\n",
            "0     Hans-Böckler-Str.      71081.0      NORMAL_VENTURE        1967.565648   \n",
            "1       Liegnitzer Str.      55708.0      NORMAL_VENTURE        1967.565648   \n",
            "2             Rascheweg      74148.0      DESIGN_CLASS_I        1967.565648   \n",
            "3               Am Diek     664000.0      NORMAL_VENTURE        1967.565648   \n",
            "4  Emil-Schniewind-Str.      75682.0      NORMAL_VENTURE        1967.565648   \n",
            "\n",
            "         WFL  ... PRIOR_DAMAGES  UVV-KZ  UNDERWRITER              PARTY-ID  \\\n",
            "0   69.00000  ...             0       1            Y  N00WXYAWXFD704PT4712   \n",
            "1   65.00000  ...             0       1            Y  YH8XZ8AWXFD704PT4713   \n",
            "2   75.00000  ...             0       1            Y  AIPAVQEWXFD704PT4713   \n",
            "3  106.24368  ...             0       1            Y  GG0UA4KWXFD704PT4715   \n",
            "4  119.00000  ...             0       1            Y  P6XU2FAWXFD704PT4712   \n",
            "\n",
            "  contract_year  PIPE_PREMIUM_AMOUNT  YEAR DAMAGE DAMAGE_FLOOD_ZONE  \\\n",
            "0    2014-01-01              4.55070  2014      0               1.0   \n",
            "1    2014-01-01              4.54080  2014      0               1.0   \n",
            "2    2014-01-01              3.18120  2014      0               1.0   \n",
            "3    2014-01-01            154.60908  2014      0               1.0   \n",
            "4    2014-01-01              5.89380  2014      0               1.0   \n",
            "\n",
            "  DAMAGE_HEAVY_RAIN_ZONE  \n",
            "0               1.727273  \n",
            "1               1.931034  \n",
            "2               1.962963  \n",
            "3               1.931034  \n",
            "4               1.768000  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3k-fugN17z",
        "outputId": "d5b64bb9-e982-4202-b434-69f852f2b392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    10203688\n",
            "1      170852\n",
            "Name: count, dtype: int64\n",
            "Unnamed: 0                      0\n",
            "ANO_SID                        50\n",
            "CORPORATE_DEVISION              0\n",
            "ORTPLZ                          0\n",
            "ORTS-NAME                      15\n",
            "STRASSE                      8516\n",
            "SUM_INSURED                 14832\n",
            "CONSTRACTION_DESIGN       1083360\n",
            "CONSTRUCTION_YEAR               0\n",
            "WFL                         14996\n",
            "ZONE                       877533\n",
            "SF-SYSTEM                 8713940\n",
            "TYPE_OF_DEDUCTIBLE              0\n",
            "DRAIN_PIPE_INSURED              0\n",
            "PRODUCTLINE               1583747\n",
            "PRIOR_DAMAGES                   0\n",
            "UVV-KZ                          0\n",
            "UNDERWRITER                     0\n",
            "PARTY-ID                      191\n",
            "contract_year                   0\n",
            "PIPE_PREMIUM_AMOUNT           164\n",
            "YEAR                            0\n",
            "DAMAGE                          0\n",
            "DAMAGE_FLOOD_ZONE               0\n",
            "DAMAGE_HEAVY_RAIN_ZONE          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(contract_class['DAMAGE'].value_counts())\n",
        "\n",
        "\n",
        "na_counts = contract_class.isna().sum()\n",
        "\n",
        "print(na_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoya1IqoQlP9"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKlJomDBmkF0"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWuhhszlQyyR",
        "outputId": "ffe95499-1e43-49f7-f8c5-d3d8d9cd1d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    10203688\n",
            "1      170852\n",
            "Name: count, dtype: int64\n",
            "DAMAGE\n",
            "0    7680154\n",
            "1     112491\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Choose variables where it makes logical sense\n",
        "\n",
        "initial_features = contract_class.loc[:, ['ANO_SID','CORPORATE_DEVISION','ORTPLZ','ZONE', 'PRODUCTLINE', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE','DAMAGE_FLOOD_ZONE','DAMAGE_HEAVY_RAIN_ZONE']]\n",
        "\n",
        "print(initial_features['DAMAGE'].value_counts())\n",
        "\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "print(initial_features_clean['DAMAGE'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fTOzfKS3VKM",
        "outputId": "b6f55fc1-593f-49b9-b64c-ae045aa1329e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ANO_SID  ORTPLZ  CONSTRUCTION_YEAR    WFL  DRAIN_PIPE_INSURED  \\\n",
            "0  4114028.0   42109        1967.565648   69.0                   0   \n",
            "1  4114039.0   42277        1967.565648   65.0                   0   \n",
            "2  4114045.0   42389        1967.565648   75.0                   0   \n",
            "4  4114055.0   42553        1967.565648  119.0                   0   \n",
            "5  4114057.0   42113        1967.565648  100.0                   0   \n",
            "\n",
            "   PRIOR_DAMAGES  UVV-KZ  DAMAGE  DAMAGE_FLOOD_ZONE  DAMAGE_HEAVY_RAIN_ZONE  \\\n",
            "0              0       1       0                1.0                1.727273   \n",
            "1              0       1       0                1.0                1.931034   \n",
            "2              0       1       0                1.0                1.962963   \n",
            "4              0       1       0                1.0                1.768000   \n",
            "5              0       1       0                1.0                1.824324   \n",
            "\n",
            "   ...  ZONE_4  ZONE_4.0  ZONE_5  ZONE_5.0  ZONE_6  ZONE_6.0  ZONE_7  \\\n",
            "0  ...   False     False   False     False   False     False   False   \n",
            "1  ...   False     False   False     False   False     False   False   \n",
            "2  ...   False     False   False     False   False     False   False   \n",
            "4  ...   False     False   False     False   False     False   False   \n",
            "5  ...   False     False   False     False   False     False   False   \n",
            "\n",
            "   ZONE_7.0  ZONE_8  ZONE_8.0  \n",
            "0     False   False     False  \n",
            "1     False   False     False  \n",
            "2     False   False     False  \n",
            "4     False   False     False  \n",
            "5     False   False     False  \n",
            "\n",
            "[5 rows x 79 columns]\n"
          ]
        }
      ],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "print(features_binary.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwwN1Fk9-mx"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g2tRFkvL99hn"
      },
      "outputs": [],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['ANO_SID','DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split into test and training\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize RandomUnderSampler\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EJMfXDqqAZOZ"
      },
      "outputs": [],
      "source": [
        "# Initializing Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Training the classifier\n",
        "rf_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Making probability predictions\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vwjrTVhFXj",
        "outputId": "0989a2f0-dd6b-4f21-9095-ef94c71420c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7693870309760037\n",
            "Confusion Matrix:\n",
            "[[1182464  353524]\n",
            " [   5893   16648]]\n",
            "True Positives: 16648\n",
            "False Positives: 353524\n",
            "True Negatives: 1182464\n",
            "False Negatives: 5893\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.77      0.87   1535988\n",
            "           1       0.04      0.74      0.08     22541\n",
            "\n",
            "    accuracy                           0.77   1558529\n",
            "   macro avg       0.52      0.75      0.48   1558529\n",
            "weighted avg       0.98      0.77      0.86   1558529\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "\n",
        "# Converting probabilities to class predictions\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "# With undersampling accuracy gets worse, but we detect more TRUE Positives. Still way more false positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTixu8nHavRD",
        "outputId": "760b1ddb-e7da-42b9-c002-134d83cdb3cd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "ORTPLZ: 0.19533521377215407\n",
            "CONSTRUCTION_YEAR: 0.14470950311335481\n",
            "WFL: 0.17196384642395823\n",
            "DRAIN_PIPE_INSURED: 0.0\n",
            "PRIOR_DAMAGES: 0.005339127571436116\n",
            "UVV-KZ: 0.013669806617498146\n",
            "DAMAGE_FLOOD_ZONE: 0.06159186743348311\n",
            "DAMAGE_HEAVY_RAIN_ZONE: 0.15287015508671584\n",
            "CORPORATE_DEVISION_VHV: 0.15697117376544298\n",
            "CONSTRACTION_DESIGN_CARAVAN_MOTORHOME: 7.219867942986655e-06\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_I: 0.00025946753653168924\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_II: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_III: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_IV: 0.0\n",
            "CONSTRACTION_DESIGN_DESIGN_CLASS_V: 3.1502769315460096e-07\n",
            "CONSTRACTION_DESIGN_NORMAL_VENTURE: 0.001125648718421881\n",
            "CONSTRACTION_DESIGN_PREDOMINANTLY_WOODEN_ROOF: 0.00016591472812097174\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE: 0.000977190087321449\n",
            "CONSTRACTION_DESIGN_PREFAB_HOUSE_I: 0.0\n",
            "PRODUCTLINE_Kompakt: 0.012119545985870091\n",
            "PRODUCTLINE_Plus: 0.002588631439404429\n",
            "PRODUCTLINE_Premium: 0.0021154620100385557\n",
            "PRODUCTLINE_Sonst: 0.023867074370793294\n",
            "PRODUCTLINE_Top: 0.005560693900701222\n",
            "UNDERWRITER_Y: 0.008492885633342879\n",
            "ZONE_1.0: 0.0023003724918297433\n",
            "ZONE_2.0: 0.000774802625694146\n",
            "ZONE_3.0: 0.0007448378495491197\n",
            "ZONE_4.0: 0.0005267133804916277\n",
            "ZONE_5.0: 0.0003161572704902607\n",
            "ZONE_6.0: 5.684124893694717e-05\n",
            "ZONE_7.0: 4.684711796440081e-05\n",
            "ZONE_8.0: 2.8192200024379022e-05\n",
            "ZONE_0: 0.0006612189068065513\n",
            "ZONE_0.0: 4.230932695539329e-05\n",
            "ZONE_1: 0.003943032724834236\n",
            "ZONE_1.0: 0.00022001148140041746\n",
            "ZONE_2: 0.001216339750392311\n",
            "ZONE_2.0: 0.00036845454752362046\n",
            "ZONE_3: 0.003745083895931833\n",
            "ZONE_3.0: 0.0003623975201814445\n",
            "ZONE_4: 0.0029184920235655783\n",
            "ZONE_4.0: 0.00029711267840341313\n",
            "ZONE_5: 0.00261487806501289\n",
            "ZONE_5.0: 0.0001275912201347531\n",
            "ZONE_6: 0.00013152380082952507\n",
            "ZONE_6.0: 2.551128780120361e-05\n",
            "ZONE_7: 8.503196550976576e-05\n",
            "ZONE_7.0: 2.235065573781362e-05\n",
            "ZONE_8: 6.30100812687986e-05\n",
            "ZONE_8.0: 3.141397157565632e-05\n",
            "ZONE_1.0: 0.0016171152637288971\n",
            "ZONE_2.0: 0.0006417651535508322\n",
            "ZONE_3.0: 0.0006812569279916431\n",
            "ZONE_4.0: 0.0005509196426572424\n",
            "ZONE_5.0: 0.00039386488358045106\n",
            "ZONE_6.0: 5.878784240798806e-05\n",
            "ZONE_7.0: 5.910665002621378e-05\n",
            "ZONE_8.0: 2.2187899356125132e-05\n",
            "ZONE_0: 0.0004547842111783059\n",
            "ZONE_0.0: 4.1477603245659517e-05\n",
            "ZONE_1: 0.003318988354351579\n",
            "ZONE_1.0: 0.0002506588341931994\n",
            "ZONE_2: 0.0011951606207665944\n",
            "ZONE_2.0: 0.00032609690235634975\n",
            "ZONE_3: 0.0032613389520423667\n",
            "ZONE_3.0: 0.0003809143316049769\n",
            "ZONE_4: 0.0023435016884438263\n",
            "ZONE_4.0: 0.00027820126168403886\n",
            "ZONE_5: 0.002229556863150457\n",
            "ZONE_5.0: 0.00013743215974457423\n",
            "ZONE_6: 0.00013319053480628331\n",
            "ZONE_6.0: 2.6694372757146227e-05\n",
            "ZONE_7: 8.403105067663376e-05\n",
            "ZONE_7.0: 2.6303701633597686e-05\n",
            "ZONE_8: 6.760831395756804e-05\n",
            "ZONE_8.0: 1.7784801035638917e-05\n"
          ]
        }
      ],
      "source": [
        "# Feature-importnace analysis\n",
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "# Display results\n",
        "print(\"Feature Importance:\")\n",
        "for i, feature in enumerate(X_train.columns):\n",
        "    print(f\"{feature}: {feature_importance[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest with SMOOTE Resampling"
      ],
      "metadata": {
        "id": "KaRssmCHzwZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = features_binary.drop(columns=['ANO_SID','DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split into test and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print the shape of resampled data\n",
        "print('Original dataset shape:', y_train.value_counts())\n",
        "print('Resampled dataset shape:', y_resampled.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOskdmWL0CJs",
        "outputId": "02cc4cc2-6ac4-4466-abff-099880f8e0cb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: DAMAGE\n",
            "0    6144166\n",
            "1      89950\n",
            "Name: count, dtype: int64\n",
            "Resampled dataset shape: DAMAGE\n",
            "0    6144166\n",
            "1    6144166\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "\n",
        "# Training the classifier\n",
        "rf_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Making probability predictions\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "lrgbtGLn1Eqr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "\n",
        "# Converting probabilities to class predictions\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generating confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Displaying confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp5ZC1gg1J_F",
        "outputId": "b45f643c-05fc-4e63-e8a9-406b7cd6a4d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9743245072757709\n",
            "Confusion Matrix:\n",
            "[[1510358   25630]\n",
            " [  14386    8155]]\n",
            "True Positives: 8155\n",
            "False Positives: 25630\n",
            "True Negatives: 1510358\n",
            "False Negatives: 14386\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99   1535988\n",
            "           1       0.24      0.36      0.29     22541\n",
            "\n",
            "    accuracy                           0.97   1558529\n",
            "   macro avg       0.62      0.67      0.64   1558529\n",
            "weighted avg       0.98      0.97      0.98   1558529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhtW_D_ljQv"
      },
      "source": [
        "## Random Forest with Rolling window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7mZ1DyNEoANN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81184a79-eade-4931-f3cb-f0a5a9289d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    10203688\n",
            "1      170852\n",
            "Name: count, dtype: int64\n",
            "DAMAGE\n",
            "0    7680154\n",
            "1     112491\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Choose variables where it makes logical sense\n",
        "\n",
        "initial_features = contract_class.loc[:, ['ANO_SID','CORPORATE_DEVISION','ORTPLZ','ZONE', 'PRODUCTLINE', 'CONSTRACTION_DESIGN','CONSTRUCTION_YEAR','WFL','ZONE','DRAIN_PIPE_INSURED', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER','DAMAGE','DAMAGE_FLOOD_ZONE','DAMAGE_HEAVY_RAIN_ZONE','YEAR']]\n",
        "\n",
        "print(initial_features['DAMAGE'].value_counts())\n",
        "\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "print(initial_features_clean['DAMAGE'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "pir7CO9ioRJd"
      },
      "outputs": [],
      "source": [
        "# Choose columns to encode to binary variables\n",
        "\n",
        "columns_to_encode = ['CORPORATE_DEVISION','CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create Binary Variables\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gSk1hjJqoVi_"
      },
      "outputs": [],
      "source": [
        "# Define feature and target\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE', 'ANO_SID'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "shjdeTf2l191",
        "outputId": "086d8556-03c7-4de3-8132-0b74943c4742"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    692820\n",
            "           1       0.33      0.27      0.29      9020\n",
            "\n",
            "    accuracy                           0.98    701840\n",
            "   macro avg       0.66      0.63      0.64    701840\n",
            "weighted avg       0.98      0.98      0.98    701840\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[687958   4862]\n",
            " [  6621   2399]]\n",
            "True Positives: 2399\n",
            "False Positives: 4862\n",
            "True Negatives: 687958\n",
            "False Negatives: 6621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:30<04:31, 30.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2016:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    719837\n",
            "           1       0.38      0.27      0.31     10068\n",
            "\n",
            "    accuracy                           0.98    729905\n",
            "   macro avg       0.68      0.63      0.65    729905\n",
            "weighted avg       0.98      0.98      0.98    729905\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[715444   4393]\n",
            " [  7396   2672]]\n",
            "True Positives: 2672\n",
            "False Positives: 4393\n",
            "True Negatives: 715444\n",
            "False Negatives: 7396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [01:02<04:12, 31.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2017:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    680978\n",
            "           1       0.35      0.25      0.29      9784\n",
            "\n",
            "    accuracy                           0.98    690762\n",
            "   macro avg       0.67      0.62      0.64    690762\n",
            "weighted avg       0.98      0.98      0.98    690762\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[676509   4469]\n",
            " [  7346   2438]]\n",
            "True Positives: 2438\n",
            "False Positives: 4469\n",
            "True Negatives: 676509\n",
            "False Negatives: 7346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:36<03:48, 32.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2018:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    682378\n",
            "           1       0.27      0.16      0.20     10521\n",
            "\n",
            "    accuracy                           0.98    692899\n",
            "   macro avg       0.63      0.58      0.60    692899\n",
            "weighted avg       0.98      0.98      0.98    692899\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[677730   4648]\n",
            " [  8825   1696]]\n",
            "True Positives: 1696\n",
            "False Positives: 4648\n",
            "True Negatives: 677730\n",
            "False Negatives: 8825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [02:09<03:15, 32.54s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2019:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    687887\n",
            "           1       0.27      0.17      0.21     11485\n",
            "\n",
            "    accuracy                           0.98    699372\n",
            "   macro avg       0.63      0.58      0.60    699372\n",
            "weighted avg       0.97      0.98      0.98    699372\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[682517   5370]\n",
            " [  9527   1958]]\n",
            "True Positives: 1958\n",
            "False Positives: 5370\n",
            "True Negatives: 682517\n",
            "False Negatives: 9527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [02:41<02:43, 32.67s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2020:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    697527\n",
            "           1       0.29      0.18      0.22     13353\n",
            "\n",
            "    accuracy                           0.98    710880\n",
            "   macro avg       0.64      0.58      0.60    710880\n",
            "weighted avg       0.97      0.98      0.97    710880\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[691690   5837]\n",
            " [ 10990   2363]]\n",
            "True Positives: 2363\n",
            "False Positives: 5837\n",
            "True Negatives: 691690\n",
            "False Negatives: 10990\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [03:14<02:10, 32.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2021:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    703570\n",
            "           1       0.28      0.18      0.22     14557\n",
            "\n",
            "    accuracy                           0.97    718127\n",
            "   macro avg       0.63      0.58      0.60    718127\n",
            "weighted avg       0.97      0.97      0.97    718127\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[696797   6773]\n",
            " [ 11973   2584]]\n",
            "True Positives: 2584\n",
            "False Positives: 6773\n",
            "True Negatives: 696797\n",
            "False Negatives: 11973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [03:48<01:39, 33.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2022:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    713366\n",
            "           1       0.20      0.17      0.18     12241\n",
            "\n",
            "    accuracy                           0.97    725607\n",
            "   macro avg       0.59      0.58      0.59    725607\n",
            "weighted avg       0.97      0.97      0.97    725607\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[705342   8024]\n",
            " [ 10186   2055]]\n",
            "True Positives: 2055\n",
            "False Positives: 8024\n",
            "True Negatives: 705342\n",
            "False Negatives: 10186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [04:24<01:08, 34.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2023:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    716445\n",
            "           1       0.18      0.15      0.16     10366\n",
            "\n",
            "    accuracy                           0.98    726811\n",
            "   macro avg       0.59      0.57      0.58    726811\n",
            "weighted avg       0.98      0.98      0.98    726811\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[709686   6759]\n",
            " [  8854   1512]]\n",
            "True Positives: 1512\n",
            "False Positives: 6759\n",
            "True Negatives: 709686\n",
            "False Negatives: 8854\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [04:57<00:33, 33.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2024:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99    721440\n",
            "           1       0.04      0.14      0.06      1900\n",
            "\n",
            "    accuracy                           0.99    723340\n",
            "   macro avg       0.52      0.56      0.53    723340\n",
            "weighted avg       1.00      0.99      0.99    723340\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[714719   6721]\n",
            " [  1643    257]]\n",
            "True Positives: 257\n",
            "False Positives: 6721\n",
            "True Negatives: 714719\n",
            "False Negatives: 1643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [05:32<00:00, 33.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year: 2015, Recall Score: 0.2659645232815965\n",
            "Year: 2016, Recall Score: 0.2653953118792213\n",
            "Year: 2017, Recall Score: 0.2491823385118561\n",
            "Year: 2018, Recall Score: 0.16120140671038874\n",
            "Year: 2019, Recall Score: 0.17048323900740095\n",
            "Year: 2020, Recall Score: 0.17696397813225492\n",
            "Year: 2021, Recall Score: 0.1775091021501683\n",
            "Year: 2022, Recall Score: 0.16787844130381505\n",
            "Year: 2023, Recall Score: 0.14586147019100906\n",
            "Year: 2024, Recall Score: 0.13526315789473684\n",
            "Combined probabilities for all years:\n",
            "   ORTPLZ  CONSTRUCTION_YEAR    WFL  DRAIN_PIPE_INSURED  PRIOR_DAMAGES  \\\n",
            "0   42109        1967.565648   69.0                   0              0   \n",
            "1   42277        1967.565648   65.0                   0              0   \n",
            "2   42389        1967.565648   75.0                   0              0   \n",
            "3   42553        1967.565648  119.0                   0              0   \n",
            "4   42113        1967.565648  100.0                   0              0   \n",
            "\n",
            "   UVV-KZ  DAMAGE_FLOOD_ZONE  DAMAGE_HEAVY_RAIN_ZONE  YEAR  \\\n",
            "0       1                1.0                1.727273  2015   \n",
            "1       1                1.0                1.931034  2015   \n",
            "2       1                1.0                1.962963  2015   \n",
            "3       1                1.0                1.768000  2015   \n",
            "4       1                1.0                1.824324  2015   \n",
            "\n",
            "   CORPORATE_DEVISION_VHV  ...  ZONE_4.0.3  ZONE_5.1  ZONE_5.0.3  ZONE_6.1  \\\n",
            "0                    True  ...       False     False       False     False   \n",
            "1                    True  ...        True     False       False     False   \n",
            "2                    True  ...       False     False       False     False   \n",
            "3                    True  ...       False     False       False     False   \n",
            "4                    True  ...        True     False       False     False   \n",
            "\n",
            "   ZONE_6.0.3  ZONE_7.1  ZONE_7.0.3  ZONE_8.1  ZONE_8.0.3  Probability  \n",
            "0       False     False       False     False       False          0.0  \n",
            "1       False     False       False     False       False          0.0  \n",
            "2       False     False       False     False       False          0.0  \n",
            "3       False     False       False     False       False          0.0  \n",
            "4       False     False       False     False       False          0.0  \n",
            "\n",
            "[5 rows x 79 columns]\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "    # Create a DataFrame for the probabilities\n",
        "    probabilities_df = pd.DataFrame({'Probability': y_prob})\n",
        "\n",
        "    # Combine the probabilities with the original test data for the year\n",
        "    combined_df = X_test.copy()\n",
        "    combined_df['Probability'] = probabilities_df['Probability'].values\n",
        "\n",
        "    # Save the combined DataFrame to a CSV file\n",
        "    combined_df.to_csv(f'probabilities_{test_year}.csv', index=False)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")\n",
        "\n",
        "\n",
        "# Combine all the CSV files into a single DataFrame\n",
        "combined_all_years = pd.concat([pd.read_csv(f'probabilities_{year}.csv') for year in years[1:]])\n",
        "\n",
        "# Save the combined DataFrame to a CSV file\n",
        "combined_all_years.to_csv('combined_probabilities_all_years.csv', index=False)\n",
        "\n",
        "print(\"Combined probabilities for all years:\")\n",
        "print(combined_all_years.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the entries in the combined probabilities DataFrame\n",
        "\n",
        "\n",
        "\n",
        "num_entries = combined_all_years.shape[0]\n",
        "\n",
        "print(\"Number of entries in the combined probabilities DataFrame:\", num_entries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk1s99bqAlYf",
        "outputId": "cd146a29-89fd-47e1-ca24-5b0be55963d7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in the combined probabilities DataFrame: 7119543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTsXs3AgLwAE"
      },
      "source": [
        "## Random Forrest with expanding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZqoHusLLqif",
        "outputId": "6da7cdad-3382-4c25-ca44-0f147a8e42b6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2015: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2015:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [06:55<1:02:23, 415.99s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    692820\n",
            "           1       0.79      0.21      0.33      9020\n",
            "\n",
            "    accuracy                           0.99    701840\n",
            "   macro avg       0.89      0.60      0.66    701840\n",
            "weighted avg       0.99      0.99      0.99    701840\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[692323    497]\n",
            " [  7139   1881]]\n",
            "True Positives: 1881\n",
            "False Positives: 497\n",
            "True Negatives: 692323\n",
            "False Negatives: 7139\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2016: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [22:24<1:35:40, 717.55s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    719837\n",
            "           1       0.95      0.20      0.32     10068\n",
            "\n",
            "    accuracy                           0.99    729905\n",
            "   macro avg       0.97      0.60      0.66    729905\n",
            "weighted avg       0.99      0.99      0.99    729905\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[719724    113]\n",
            " [  8096   1972]]\n",
            "True Positives: 1972\n",
            "False Positives: 113\n",
            "True Negatives: 719724\n",
            "False Negatives: 8096\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for year 2017: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20}\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [47:43<2:06:22, 1083.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    680978\n",
            "           1       0.57      0.22      0.32      9784\n",
            "\n",
            "    accuracy                           0.99    690762\n",
            "   macro avg       0.78      0.61      0.66    690762\n",
            "weighted avg       0.98      0.99      0.98    690762\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[679315   1663]\n",
            " [  7616   2168]]\n",
            "True Positives: 2168\n",
            "False Positives: 1663\n",
            "True Negatives: 679315\n",
            "False Negatives: 7616\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2018: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [1:21:21<2:25:14, 1452.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    682378\n",
            "           1       0.44      0.13      0.20     10521\n",
            "\n",
            "    accuracy                           0.98    692899\n",
            "   macro avg       0.71      0.56      0.60    692899\n",
            "weighted avg       0.98      0.98      0.98    692899\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[680645   1733]\n",
            " [  9161   1360]]\n",
            "True Positives: 1360\n",
            "False Positives: 1733\n",
            "True Negatives: 680645\n",
            "False Negatives: 9161\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2019: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20}\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [2:08:19<2:42:04, 1944.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    687887\n",
            "           1       0.50      0.13      0.21     11485\n",
            "\n",
            "    accuracy                           0.98    699372\n",
            "   macro avg       0.74      0.57      0.60    699372\n",
            "weighted avg       0.98      0.98      0.98    699372\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[686348   1539]\n",
            " [  9944   1541]]\n",
            "True Positives: 1541\n",
            "False Positives: 1539\n",
            "True Negatives: 686348\n",
            "False Negatives: 9944\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2020: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20}\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [3:11:23<2:51:21, 2570.31s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    697527\n",
            "           1       0.52      0.14      0.23     13353\n",
            "\n",
            "    accuracy                           0.98    710880\n",
            "   macro avg       0.75      0.57      0.61    710880\n",
            "weighted avg       0.98      0.98      0.98    710880\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[695729   1798]\n",
            " [ 11427   1926]]\n",
            "True Positives: 1926\n",
            "False Positives: 1798\n",
            "True Negatives: 695729\n",
            "False Negatives: 11427\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for year 2021: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 10}\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [4:30:08<2:43:43, 3274.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    703570\n",
            "           1       0.77      0.11      0.19     14557\n",
            "\n",
            "    accuracy                           0.98    718127\n",
            "   macro avg       0.88      0.55      0.59    718127\n",
            "weighted avg       0.98      0.98      0.97    718127\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[703115    455]\n",
            " [ 12995   1562]]\n",
            "True Positives: 1562\n",
            "False Positives: 455\n",
            "True Negatives: 703115\n",
            "False Negatives: 12995\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for year 2022: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [6:05:56<2:15:24, 4062.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    713366\n",
            "           1       0.33      0.13      0.19     12241\n",
            "\n",
            "    accuracy                           0.98    725607\n",
            "   macro avg       0.66      0.56      0.59    725607\n",
            "weighted avg       0.97      0.98      0.98    725607\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[710071   3295]\n",
            " [ 10598   1643]]\n",
            "True Positives: 1643\n",
            "False Positives: 3295\n",
            "True Negatives: 710071\n",
            "False Negatives: 10598\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2023: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [8:01:40<1:22:42, 4962.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    716445\n",
            "           1       0.30      0.12      0.17     10366\n",
            "\n",
            "    accuracy                           0.98    726811\n",
            "   macro avg       0.64      0.56      0.58    726811\n",
            "weighted avg       0.98      0.98      0.98    726811\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[713638   2807]\n",
            " [  9161   1205]]\n",
            "True Positives: 1205\n",
            "False Positives: 2807\n",
            "True Negatives: 713638\n",
            "False Negatives: 9161\n",
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Best parameters for year 2024: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 20}\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [10:24:51<00:00, 3749.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    721440\n",
            "           1       0.25      0.07      0.12      1900\n",
            "\n",
            "    accuracy                           1.00    723340\n",
            "   macro avg       0.62      0.54      0.56    723340\n",
            "weighted avg       1.00      1.00      1.00    723340\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[721015    425]\n",
            " [  1758    142]]\n",
            "True Positives: 142\n",
            "False Positives: 425\n",
            "True Negatives: 721015\n",
            "False Negatives: 1758\n",
            "Year: 2015, Recall Score: 0.20853658536585365\n",
            "Year: 2016, Recall Score: 0.19586809694080254\n",
            "Year: 2017, Recall Score: 0.22158626328699918\n",
            "Year: 2018, Recall Score: 0.12926527896587778\n",
            "Year: 2019, Recall Score: 0.13417501088376144\n",
            "Year: 2020, Recall Score: 0.14423725005616717\n",
            "Year: 2021, Recall Score: 0.10730232877653363\n",
            "Year: 2022, Recall Score: 0.13422106037088474\n",
            "Year: 2023, Recall Score: 0.11624541771174995\n",
            "Year: 2024, Recall Score: 0.07473684210526316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 20],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(1, len(years))):\n",
        "    test_year = years[i]\n",
        "    train_years = years[:i]  # All years up to the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'].isin(train_years)]\n",
        "    y_train = y[features_binary['YEAR'].isin(train_years)]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize the Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Initialize the SMOTE resampler\n",
        "    smote = SMOTE(random_state=42)\n",
        "\n",
        "    # Create a pipeline with SMOTE and Random Forest classifier\n",
        "    pipeline = Pipeline([\n",
        "        ('smote', smote),\n",
        "        ('rf', rf_classifier)\n",
        "    ])\n",
        "\n",
        "    # Perform Grid Search with cross-validation\n",
        "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid,\n",
        "                               cv=3, n_jobs=-1, verbose=2, scoring='recall')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model from Grid Search\n",
        "    best_rf_classifier = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions (probabilities)\n",
        "    y_prob = best_rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the best parameters for the current year\n",
        "    print(f\"Best parameters for year {test_year}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "rWhEv4t4b5Db",
        "outputId": "eda2bdca-342b-4f17-8e34-bbb98301bab9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'combined_all_years_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-41a3732430a6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Count the entries in the combined probabilities DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_all_years_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of entries in the combined probabilities DataFrame:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_all_years_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNPRV0LutSjd"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OXNnLuCbdc-T"
      },
      "outputs": [],
      "source": [
        "# Define initial features\n",
        "initial_features = contract_class.loc[:, ['CORPORATE_DEVISION', 'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL', 'ZONE', 'DRAIN_PIPE_INSURED', 'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'DAMAGE', 'YEAR']]\n",
        "initial_features_clean = initial_features.dropna()\n",
        "\n",
        "# Define feature and target\n",
        "columns_to_encode = ['CORPORATE_DEVISION', 'CONSTRACTION_DESIGN', 'PRODUCTLINE', 'UNDERWRITER', 'ZONE']\n",
        "\n",
        "# Create binary variables using one-hot encoding\n",
        "features_binary = pd.get_dummies(initial_features_clean, columns=columns_to_encode, drop_first=True)\n",
        "\n",
        "X = features_binary.drop(columns=['DAMAGE'])\n",
        "y = features_binary['DAMAGE']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate continuous and discrete features\n",
        "continuous_features = ['SUM_INSURED', 'CONSTRUCTION_YEAR']\n",
        "# The discrete features need to be adjusted after one-hot encoding\n",
        "discrete_features = list(set(X.columns) - set(continuous_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTjSjOWoF5u",
        "outputId": "00a0427a-d56c-415e-f6f2-1944c48c5d11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report for year 2015:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:03<00:27,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773616   1655]\n",
            " [  8536   1200]]\n",
            "True Positives: 1200\n",
            "False Positives: 1655\n",
            "True Negatives: 773616\n",
            "False Negatives: 8536\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:06<00:26,  3.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.48      0.11      0.18     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.74      0.55      0.59    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804964   1258]\n",
            " [  9640   1175]]\n",
            "True Positives: 1175\n",
            "False Positives: 1258\n",
            "True Negatives: 804964\n",
            "False Negatives: 9640\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:09<00:22,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.42      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760286   1383]\n",
            " [  9455   1004]]\n",
            "True Positives: 1004\n",
            "False Positives: 1383\n",
            "True Negatives: 760286\n",
            "False Negatives: 9455\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:12<00:18,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.16      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762597   1752]\n",
            " [ 11106    334]]\n",
            "True Positives: 334\n",
            "False Positives: 1752\n",
            "True Negatives: 762597\n",
            "False Negatives: 11106\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:15<00:15,  3.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    771495\n",
            "           1       0.09      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.54      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.97    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[767538   3957]\n",
            " [ 12103    377]]\n",
            "True Positives: 377\n",
            "False Positives: 3957\n",
            "True Negatives: 767538\n",
            "False Negatives: 12103\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:18<00:12,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    780559\n",
            "           1       0.08      0.03      0.05     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.53      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[775127   5432]\n",
            " [ 13900    476]]\n",
            "True Positives: 476\n",
            "False Positives: 5432\n",
            "True Negatives: 775127\n",
            "False Negatives: 13900\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:21<00:09,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98    788098\n",
            "           1       0.05      0.04      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.52      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[777761  10337]\n",
            " [ 15188    582]]\n",
            "True Positives: 582\n",
            "False Positives: 10337\n",
            "True Negatives: 777761\n",
            "False Negatives: 15188\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:24<00:06,  3.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    797092\n",
            "           1       0.04      0.05      0.05     13298\n",
            "\n",
            "    accuracy                           0.96    810390\n",
            "   macro avg       0.51      0.52      0.51    810390\n",
            "weighted avg       0.97      0.96      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[780519  16573]\n",
            " [ 12590    708]]\n",
            "True Positives: 708\n",
            "False Positives: 16573\n",
            "True Negatives: 780519\n",
            "False Negatives: 12590\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:27<00:03,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98    800711\n",
            "           1       0.04      0.07      0.05     11149\n",
            "\n",
            "    accuracy                           0.96    811860\n",
            "   macro avg       0.51      0.52      0.51    811860\n",
            "weighted avg       0.97      0.96      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[779298  21413]\n",
            " [ 10356    793]]\n",
            "True Positives: 793\n",
            "False Positives: 21413\n",
            "True Negatives: 779298\n",
            "False Negatives: 10356\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:30<00:00,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98    806672\n",
            "           1       0.01      0.08      0.01      2049\n",
            "\n",
            "    accuracy                           0.96    808721\n",
            "   macro avg       0.50      0.52      0.49    808721\n",
            "weighted avg       1.00      0.96      0.98    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[775821  30851]\n",
            " [  1877    172]]\n",
            "True Positives: 172\n",
            "False Positives: 30851\n",
            "True Negatives: 775821\n",
            "False Negatives: 1877\n",
            "Year: 2015, Recall Score: 0.12325390304026294\n",
            "Year: 2016, Recall Score: 0.10864539990753583\n",
            "Year: 2017, Recall Score: 0.09599388086815183\n",
            "Year: 2018, Recall Score: 0.029195804195804195\n",
            "Year: 2019, Recall Score: 0.030208333333333334\n",
            "Year: 2020, Recall Score: 0.03311074012242626\n",
            "Year: 2021, Recall Score: 0.03690551680405834\n",
            "Year: 2022, Recall Score: 0.0532410888855467\n",
            "Year: 2023, Recall Score: 0.07112745537716388\n",
            "Year: 2024, Recall Score: 0.08394338701805759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    train_year = years[i]\n",
        "    test_year = years[i + 1]\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'] == train_year]\n",
        "    y_train = y[features_binary['YEAR'] == train_year]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "# Train GaussianNB on continuous features\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train[continuous_features], y_train)\n",
        "\n",
        "# Train MultinomialNB on discrete features\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train[discrete_features], y_train)\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEXUyHcDbQtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srilci2A3lB6",
        "outputId": "f29d891b-722e-43a1-aee2-71b87d0b067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.99\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99   1719308\n",
            "           1       0.98      0.04      0.08     24428\n",
            "\n",
            "    accuracy                           0.99   1743736\n",
            "   macro avg       0.98      0.52      0.54   1743736\n",
            "weighted avg       0.99      0.99      0.98   1743736\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1719284      24]\n",
            " [  23369    1059]]\n",
            "True Positives: 1059\n",
            "False Positives: 24\n",
            "True Negatives: 1719284\n",
            "False Negatives: 23369\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Extracting TP, FP, TN, FN from the confusion matrix\n",
        "TN = conf_matrix[0][0]\n",
        "FP = conf_matrix[0][1]\n",
        "FN = conf_matrix[1][0]\n",
        "TP = conf_matrix[1][1]\n",
        "\n",
        "# Printing TP, FP, TN, FN\n",
        "print(\"True Positives:\", TP)\n",
        "print(\"False Positives:\", FP)\n",
        "print(\"True Negatives:\", TN)\n",
        "print(\"False Negatives:\", FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes with expanding window"
      ],
      "metadata": {
        "id": "e-6EMCOreuRE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yNjBsFwxmFB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7148187a-fc8c-4935-94ae-90a9e6bd3fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for GaussianNB in year 2015: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2015: {'alpha': 0.1}\n",
            "Classification report for year 2015:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:08<01:17,  8.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    775271\n",
            "           1       0.42      0.12      0.19      9736\n",
            "\n",
            "    accuracy                           0.99    785007\n",
            "   macro avg       0.70      0.56      0.59    785007\n",
            "weighted avg       0.98      0.99      0.98    785007\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[773620   1651]\n",
            " [  8539   1197]]\n",
            "True Positives: 1197\n",
            "False Positives: 1651\n",
            "True Negatives: 773620\n",
            "False Negatives: 8539\n",
            "Best parameters for GaussianNB in year 2016: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2016: {'alpha': 2.0}\n",
            "Classification report for year 2016:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:18<01:15,  9.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    806222\n",
            "           1       0.43      0.11      0.17     10815\n",
            "\n",
            "    accuracy                           0.99    817037\n",
            "   macro avg       0.71      0.55      0.58    817037\n",
            "weighted avg       0.98      0.99      0.98    817037\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[804652   1570]\n",
            " [  9634   1181]]\n",
            "True Positives: 1181\n",
            "False Positives: 1570\n",
            "True Negatives: 804652\n",
            "False Negatives: 9634\n",
            "Best parameters for GaussianNB in year 2017: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2017: {'alpha': 2.0}\n",
            "Classification report for year 2017:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:31<01:17, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    761669\n",
            "           1       0.40      0.10      0.16     10459\n",
            "\n",
            "    accuracy                           0.99    772128\n",
            "   macro avg       0.70      0.55      0.57    772128\n",
            "weighted avg       0.98      0.99      0.98    772128\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[760187   1482]\n",
            " [  9453   1006]]\n",
            "True Positives: 1006\n",
            "False Positives: 1482\n",
            "True Negatives: 760187\n",
            "False Negatives: 9453\n",
            "Best parameters for GaussianNB in year 2018: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2018: {'alpha': 0.1}\n",
            "Classification report for year 2018:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:48<01:20, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    764349\n",
            "           1       0.15      0.03      0.05     11440\n",
            "\n",
            "    accuracy                           0.98    775789\n",
            "   macro avg       0.57      0.51      0.52    775789\n",
            "weighted avg       0.97      0.98      0.98    775789\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[762467   1882]\n",
            " [ 11105    335]]\n",
            "True Positives: 335\n",
            "False Positives: 1882\n",
            "True Negatives: 762467\n",
            "False Negatives: 11105\n",
            "Best parameters for GaussianNB in year 2019: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2019: {'alpha': 0.1}\n",
            "Classification report for year 2019:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:08<01:19, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    771495\n",
            "           1       0.12      0.03      0.04     12480\n",
            "\n",
            "    accuracy                           0.98    783975\n",
            "   macro avg       0.55      0.51      0.52    783975\n",
            "weighted avg       0.97      0.98      0.98    783975\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[769127   2368]\n",
            " [ 12146    334]]\n",
            "True Positives: 334\n",
            "False Positives: 2368\n",
            "True Negatives: 769127\n",
            "False Negatives: 12146\n",
            "Best parameters for GaussianNB in year 2020: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2020: {'alpha': 0.1}\n",
            "Classification report for year 2020:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:32<01:13, 18.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    780559\n",
            "           1       0.11      0.03      0.04     14376\n",
            "\n",
            "    accuracy                           0.98    794935\n",
            "   macro avg       0.54      0.51      0.52    794935\n",
            "weighted avg       0.97      0.98      0.97    794935\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[777226   3333]\n",
            " [ 13976    400]]\n",
            "True Positives: 400\n",
            "False Positives: 3333\n",
            "True Negatives: 777226\n",
            "False Negatives: 13976\n",
            "Best parameters for GaussianNB in year 2021: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2021: {'alpha': 0.5}\n",
            "Classification report for year 2021:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:59<01:03, 21.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    788098\n",
            "           1       0.07      0.03      0.04     15770\n",
            "\n",
            "    accuracy                           0.97    803868\n",
            "   macro avg       0.53      0.51      0.51    803868\n",
            "weighted avg       0.96      0.97      0.97    803868\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[782902   5196]\n",
            " [ 15360    410]]\n",
            "True Positives: 410\n",
            "False Positives: 5196\n",
            "True Negatives: 782902\n",
            "False Negatives: 15360\n",
            "Best parameters for GaussianNB in year 2022: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2022: {'alpha': 0.1}\n",
            "Classification report for year 2022:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:30<00:49, 24.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99    797092\n",
            "           1       0.06      0.04      0.05     13298\n",
            "\n",
            "    accuracy                           0.97    810390\n",
            "   macro avg       0.52      0.51      0.52    810390\n",
            "weighted avg       0.97      0.97      0.97    810390\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[789534   7558]\n",
            " [ 12814    484]]\n",
            "True Positives: 484\n",
            "False Positives: 7558\n",
            "True Negatives: 789534\n",
            "False Negatives: 12814\n",
            "Best parameters for GaussianNB in year 2023: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2023: {'alpha': 0.1}\n",
            "Classification report for year 2023:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:07<00:28, 28.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99    800711\n",
            "           1       0.05      0.05      0.05     11149\n",
            "\n",
            "    accuracy                           0.97    811860\n",
            "   macro avg       0.52      0.52      0.52    811860\n",
            "weighted avg       0.97      0.97      0.97    811860\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[790632  10079]\n",
            " [ 10566    583]]\n",
            "True Positives: 583\n",
            "False Positives: 10079\n",
            "True Negatives: 790632\n",
            "False Negatives: 10566\n",
            "Best parameters for GaussianNB in year 2024: {'var_smoothing': 1e-09}\n",
            "Best parameters for MultinomialNB in year 2024: {'alpha': 0.1}\n",
            "Classification report for year 2024:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:48<00:00, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99    806672\n",
            "           1       0.01      0.05      0.01      2049\n",
            "\n",
            "    accuracy                           0.98    808721\n",
            "   macro avg       0.50      0.52      0.50    808721\n",
            "weighted avg       1.00      0.98      0.99    808721\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[793852  12820]\n",
            " [  1944    105]]\n",
            "True Positives: 105\n",
            "False Positives: 12820\n",
            "True Negatives: 793852\n",
            "False Negatives: 1944\n",
            "Year: 2015, Recall Score: 0.12294576828266228\n",
            "Year: 2016, Recall Score: 0.10920018492834027\n",
            "Year: 2017, Recall Score: 0.09618510373840711\n",
            "Year: 2018, Recall Score: 0.029283216783216784\n",
            "Year: 2019, Recall Score: 0.02676282051282051\n",
            "Year: 2020, Recall Score: 0.027824151363383415\n",
            "Year: 2021, Recall Score: 0.02599873176918199\n",
            "Year: 2022, Recall Score: 0.036396450594074294\n",
            "Year: 2023, Recall Score: 0.052291685352946454\n",
            "Year: 2024, Recall Score: 0.05124450951683748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define parameter grids for GaussianNB and MultinomialNB\n",
        "gnb_param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
        "}\n",
        "\n",
        "mnb_param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "# Create a list of unique years in the data\n",
        "years = sorted(features_binary['YEAR'].unique())\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "\n",
        "# Loop over each year for rolling window estimation\n",
        "for i in tqdm(range(1, len(years))):\n",
        "    test_year = years[i]\n",
        "    train_years = years[:i]  # All years up to the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    X_train = X[features_binary['YEAR'].isin(train_years)]\n",
        "    y_train = y[features_binary['YEAR'].isin(train_years)]\n",
        "    X_test = X[features_binary['YEAR'] == test_year]\n",
        "    y_test = y[features_binary['YEAR'] == test_year]\n",
        "\n",
        "    # Initialize GaussianNB and perform Grid Search\n",
        "    gnb = GaussianNB()\n",
        "    gnb_grid_search = GridSearchCV(estimator=gnb, param_grid=gnb_param_grid, cv=3, n_jobs=-1, scoring='recall')\n",
        "    gnb_grid_search.fit(X_train[continuous_features], y_train)\n",
        "    best_gnb = gnb_grid_search.best_estimator_\n",
        "\n",
        "    # Initialize MultinomialNB and perform Grid Search\n",
        "    mnb = MultinomialNB()\n",
        "    mnb_grid_search = GridSearchCV(estimator=mnb, param_grid=mnb_param_grid, cv=3, n_jobs=-1, scoring='recall')\n",
        "    mnb_grid_search.fit(X_train[discrete_features], y_train)\n",
        "    best_mnb = mnb_grid_search.best_estimator_\n",
        "\n",
        "    # Get predicted probabilities for continuous and discrete features\n",
        "    gnb_prob = best_gnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "    mnb_prob = best_mnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (gnb_prob + mnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the best parameters for the current year\n",
        "    print(f\"Best parameters for GaussianNB in year {test_year}: {gnb_grid_search.best_params_}\")\n",
        "    print(f\"Best parameters for MultinomialNB in year {test_year}: {mnb_grid_search.best_params_}\")\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "# Print recall scores\n",
        "for year, score in recall_scores:\n",
        "    print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNC+xTyQvRFmgJJ5aCfeca5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}