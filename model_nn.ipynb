{"cells":[{"cell_type":"markdown","metadata":{"id":"ul8FG0MadDKn"},"source":["# Neural Network"]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"D3ZcHUY1On1h"}},{"cell_type":"code","source":["# Install required libraries\n","!pip install dask[dataframe] dask-ml tensorflow\n","\n","import dask.dataframe as dd\n","from dask_ml.preprocessing import DummyEncoder, StandardScaler\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from dask_ml.model_selection import train_test_split\n","import numpy as np"],"metadata":{"id":"auzgWilTMYX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717012792434,"user_tz":-120,"elapsed":7444,"user":{"displayName":"Mina Randolf","userId":"17262056063041429157"}},"outputId":"75356e01-dcee-45ed-d820-ddb5a3a1455a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n","Requirement already satisfied: dask-ml in /usr/local/lib/python3.10/dist-packages (2024.4.4)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n","Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2023.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.0)\n","Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.1)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (7.1.0)\n","Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.0.3)\n","Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (0.3.2)\n","Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (2023.8.1)\n","Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.0.0)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (0.58.1)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.25.2)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.11.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: sparse>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask-ml) (0.15.4)\n","Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.1.4)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.8)\n","Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n","Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (6.3.3)\n","Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.0.7)\n","Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.18.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask-ml) (0.41.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->dask[dataframe]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->dask[dataframe]) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->dask[dataframe]) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (3.5.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask-ml) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive"],"metadata":{"id":"XgxCpF7I74U6","executionInfo":{"status":"ok","timestamp":1717012793577,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mina Randolf","userId":"17262056063041429157"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Load the data"],"metadata":{"id":"G9UsEZkYznAS"}},{"cell_type":"code","source":["\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define the file path and dtype\n","file_path = '/content/drive/My Drive/Capstone/Data/contract_classification.csv'\n","dtype = {\n","    'CORPORATE_DEVISION': 'category',\n","    'ORTS-NAME': 'category',\n","    'STRASSE': 'category',\n","    'CONSTRACTION_DESIGN': 'category',\n","    'ZONE': 'category',\n","    'PRODUCTLINE': 'category',\n","    'UNDERWRITER': 'category',\n","    'PARTY-ID': 'category'\n","}\n","\n","# Load data in chunks\n","df = dd.read_csv(file_path, dtype=dtype, blocksize=\"64MB\")\n","\n","# Ensure that the categories are known\n","categorical_columns = list(dtype.keys())\n","df = df.categorize(columns=categorical_columns)\n","\"\"\""],"metadata":{"id":"yVqv0p9NMhBy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717011809117,"user_tz":-120,"elapsed":146882,"user":{"displayName":"Mina Randolf","userId":"17262056063041429157"}},"outputId":"17e4fafc-c6f4-405d-fdd1-4818e55fe3e4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load the CSV file\n","file_path = '/content/drive/My Drive/Capstone/Data/contract_classification.csv'\n","df = pd.read_csv(file_path)\n","\n","# Count all observations\n","num_observations = len(df)\n","print(f\"Number of observations: {num_observations}\")\n","\n","# List all column names\n","column_names = df.columns\n","print(\"Column names:\")\n","print(column_names)\n","\n","# Display the types of the columns\n","column_types = df.dtypes\n","print(\"Column types:\")\n","print(column_types)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pR3-Ub4EOz_E","executionInfo":{"status":"ok","timestamp":1717012858773,"user_tz":-120,"elapsed":65200,"user":{"displayName":"Mina Randolf","userId":"17262056063041429157"}},"outputId":"ffe85685-fa6e-4073-89f1-1637b7f9ddd9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-8cd155ac6077>:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file_path)\n"]},{"output_type":"stream","name":"stdout","text":["Number of observations: 11574439\n","Column names:\n","Index(['ANO_SID', 'CORPORATE_DEVISION', 'ORTPLZ', 'ORTS-NAME', 'STRASSE',\n","       'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL',\n","       'ZONE', 'SF-SYSTEM', 'TYPE_OF_DEDUCTIBLE', 'DRAIN_PIPE_INSURED',\n","       'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'PARTY-ID',\n","       'contract_year', 'PIPE_PREMIUM_AMOUNT', 'YEAR', 'DAMAGE'],\n","      dtype='object')\n","Column types:\n","ANO_SID                float64\n","CORPORATE_DEVISION      object\n","ORTPLZ                 float64\n","ORTS-NAME               object\n","STRASSE                 object\n","SUM_INSURED            float64\n","CONSTRACTION_DESIGN     object\n","CONSTRUCTION_YEAR      float64\n","WFL                    float64\n","ZONE                    object\n","SF-SYSTEM              float64\n","TYPE_OF_DEDUCTIBLE       int64\n","DRAIN_PIPE_INSURED       int64\n","PRODUCTLINE             object\n","PRIOR_DAMAGES            int64\n","UVV-KZ                   int64\n","UNDERWRITER             object\n","PARTY-ID                object\n","contract_year           object\n","PIPE_PREMIUM_AMOUNT    float64\n","YEAR                     int64\n","DAMAGE                   int64\n","dtype: object\n"]}]},{"cell_type":"markdown","source":["## Preprocess the data"],"metadata":{"id":"-G08M52oQSV3"}},{"cell_type":"code","source":["\"\"\"\n","# Convert categorical columns to dummy variables\n","df = DummyEncoder(columns=categorical_columns).fit_transform(df)\n","\n","# Handle missing values\n","df = df.fillna(0)\n","\n","# Reduce memory usage by converting float64 to float32\n","float_columns = df.select_dtypes(include=['float64']).columns\n","df[float_columns] = df[float_columns].astype('float32')\n","\n","# Convert to Dask arrays for compatibility with TensorFlow\n","df = df.to_dask_array(lengths=True)\n","\"\"\""],"metadata":{"id":"PEzx7Qu3Pb-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import dask.dataframe as dd\n","from dask_ml.preprocessing import DummyEncoder, StandardScaler\n","from dask_ml.model_selection import train_test_split\n","\n","# Load the CSV file with dask and specify the dtypes for the categorical columns\n","file_path = '/content/drive/My Drive/Capstone/Data/contract_classification.csv'\n","dtype = {\n","    'CORPORATE_DEVISION': 'category',\n","    'ORTS-NAME': 'category',\n","    'STRASSE': 'category',\n","    'CONSTRACTION_DESIGN': 'category',\n","    'ZONE': 'category',\n","    'PRODUCTLINE': 'category',\n","    'UNDERWRITER': 'category',\n","    'PARTY-ID': 'category'\n","}\n","df = dd.read_csv(file_path, dtype=dtype)\n","\n","# Ensure that the categories are known\n","df = df.categorize(columns=dtype.keys())\n","\n","# Convert categorical columns to dummy variables\n","df = DummyEncoder(columns=dtype.keys()).fit_transform(df)\n","\n","# Handle missing values\n","df = df.dropna()\n","\n","# Split the data into features and target\n","X = df.drop(columns=['DAMAGE'])\n","y = df['DAMAGE']\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Compute the Dask DataFrame to get a sample to fit the scaler\n","X_scaled = X_scaled.compute()\n","y = y.compute()\n","\n","# Example: Split for the years 2014 (train) and 2015 (test)\n","def rolling_window_train_test_split(X, y, train_year, test_year):\n","    train_index = df[df['YEAR'] == train_year].index\n","    test_index = df[df['YEAR'] == test_year].index\n","    X_train, X_test = X_scaled.loc[train_index], X_scaled.loc[test_index]\n","    y_train, y_test = y.loc[train_index], y.loc[test_index]\n","    return X_train, X_test, y_train, y_test\n","\n","train_year = 2014\n","test_year = 2015\n","X_train, X_test, y_train, y_test = rolling_window_train_test_split(X, y, train_year, test_year)\n"],"metadata":{"id":"F8qH3sKnVqNp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modelling"],"metadata":{"id":"kwxXODW2YInA"}},{"cell_type":"code","source":["\"\"\"\n","years = df['contract_year'].unique().compute()\n","years.sort()\n","\n","recalls = []\n","\n","for i in range(len(years) - 1):\n","    train_year = years[i]\n","    test_year = years[i + 1]\n","\n","    # Split the data based on the year\n","    train_data = df[df['contract_year'] == train_year]\n","    test_data = df[df['contract_year'] == test_year]\n","\n","    # Split the data into features and target\n","    X_train = train_data.drop('DAMAGE', axis=1)\n","    y_train = train_data['DAMAGE']\n","    X_test = test_data.drop('DAMAGE', axis=1)\n","    y_test = test_data['DAMAGE']\n","\n","    # Convert to Dask arrays for compatibility with TensorFlow\n","    X_train = X_train.to_dask_array(lengths=True)\n","    X_test = X_test.to_dask_array(lengths=True)\n","    y_train = y_train.to_dask_array(lengths=True)\n","    y_test = y_test.to_dask_array(lengths=True)\n","\n","    # Build the neural network\n","    model = Sequential([\n","        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","        Dense(32, activation='relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n","\n","    # Train the model\n","    model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))\n","\n","    # Evaluate the model\n","    _, recall = model.evaluate(X_test, y_test)\n","    recalls.append(recall)\n","\n","    print(f'Trained on {train_year}, tested on {test_year}, Recall: {recall}')\n","\n","# Print the average recall\n","average_recall = np.mean(recalls)\n","print(f'Average Recall: {average_recall}')\n","\"\"\""],"metadata":{"id":"NlkJuSRE5QoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define and Train the Neural Network Model\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Define the neural network model\n","model = Sequential()\n","model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Recall'])\n","\n","# Print the model summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"],"metadata":{"id":"YjuqV_8yYJDn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"RLDNuc-G5p5H"}},{"cell_type":"code","source":["\"\"\"\n","# Evaluate the overall performance\n","average_recall = np.mean(recalls)\n","print(f'Average Recall over all years: {average_recall}')\n","\"\"\""],"metadata":{"id":"U5lBDe3m5rRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","loss, recall = model.evaluate(X_test, y_test)\n","print(f'Test Recall: {recall}')\n","\n","# Plot training & validation recall values\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['recall'])\n","plt.plot(history.history['val_recall'])\n","plt.title('Model recall')\n","plt.ylabel('Recall')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"J-J_p-sHYOVo"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMmMzAS4WpZmv4I8SMs6BeT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}