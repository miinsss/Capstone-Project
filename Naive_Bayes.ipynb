{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miinsss/Capstone-Project/blob/main/Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bU5iM6J_2o"
      },
      "source": [
        "# Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ENHreirWKFF9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.naive_bayes import ComplementNB, BernoulliNB\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbf_dBkuKPCj"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LksDbqsQKVuC",
        "outputId": "968a4455-245e-41b9-c362-41655cc413aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhO042Kw5kQJ",
        "outputId": "a62cf200-2cfa-4ea0-8e81-8578d0cfc2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e723c9e46e08>:3: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  contract_class = pd.read_csv(contract_class_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0    ANO_SID CORPORATE_DEVISION           Bundesland    Typ  \\\n",
            "0           0  4114028.0                VHV  Nordrhein-Westfalen  Stadt   \n",
            "1           1  4114039.0                VHV  Nordrhein-Westfalen  Stadt   \n",
            "2           2  4114045.0                VHV  Nordrhein-Westfalen  Stadt   \n",
            "3           3  4114049.0                VGV  Nordrhein-Westfalen  Stadt   \n",
            "4           4  4114055.0                VHV  Nordrhein-Westfalen  Kreis   \n",
            "\n",
            "   ORTPLZ CONSTRACTION_DESIGN  CONSTRUCTION_YEAR        WFL ZONE  ...  \\\n",
            "0   42109      NORMAL_VENTURE        1967.565648   69.00000  2.0  ...   \n",
            "1   42277      NORMAL_VENTURE        1967.565648   65.00000  4.0  ...   \n",
            "2   42389      DESIGN_CLASS_I        1967.565648   75.00000  1.0  ...   \n",
            "3   42277      NORMAL_VENTURE        1967.565648  106.24368  NaN  ...   \n",
            "4   42553      NORMAL_VENTURE        1967.565648  119.00000  2.0  ...   \n",
            "\n",
            "   DRAIN_PIPE_INSURED  PRODUCTLINE PRIOR_DAMAGES  UVV-KZ  UNDERWRITER  YEAR  \\\n",
            "0                   0        Sonst             0       1            Y  2014   \n",
            "1                   0        Basis             0       1            Y  2014   \n",
            "2                   0        Sonst             0       1            Y  2014   \n",
            "3                   0      Kompakt             0       1            Y  2014   \n",
            "4                   0        Sonst             0       1            Y  2014   \n",
            "\n",
            "   DAMAGE_HEAVY_RAIN_ZONE  LONGITUDE   LATITUDE  DAMAGE  \n",
            "0                1.727273   7.168175  51.285086       0  \n",
            "1                1.931034   7.221409  51.282877       0  \n",
            "2                1.962963   7.257295  51.272306       0  \n",
            "3                1.931034   7.226671  51.285622       0  \n",
            "4                1.768000   7.080255  51.312158       0  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the contract_classification.csv file\n",
        "contract_class_path = '/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/data_all_unique_values.csv'\n",
        "contract_class = pd.read_csv(contract_class_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify content\n",
        "print(contract_class.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3k-fugN17z",
        "outputId": "0441c330-5642-474f-e122-167034c90b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAMAGE\n",
            "0    9330675\n",
            "1     135686\n",
            "Name: count, dtype: int64\n",
            "Unnamed: 0                     0\n",
            "ANO_SID                        0\n",
            "CORPORATE_DEVISION             0\n",
            "Bundesland                     0\n",
            "Typ                            0\n",
            "ORTPLZ                         0\n",
            "CONSTRACTION_DESIGN            0\n",
            "CONSTRUCTION_YEAR              0\n",
            "WFL                            0\n",
            "ZONE                      777969\n",
            "TYPE_OF_DEDUCTIBLE             0\n",
            "DRAIN_PIPE_INSURED             0\n",
            "PRODUCTLINE                    0\n",
            "PRIOR_DAMAGES                  0\n",
            "UVV-KZ                         0\n",
            "UNDERWRITER                    0\n",
            "YEAR                           0\n",
            "DAMAGE_HEAVY_RAIN_ZONE         0\n",
            "LONGITUDE                      0\n",
            "LATITUDE                       0\n",
            "DAMAGE                         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(contract_class['DAMAGE'].value_counts())\n",
        "\n",
        "\n",
        "na_counts = contract_class.isna().sum()\n",
        "\n",
        "print(na_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoya1IqoQlP9"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNPRV0LutSjd"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "qI70yxHRt94S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZgIOL_aJhmT",
        "outputId": "3c5beb02-9d74-4f63-cd51-059cb3576e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original unique values: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-c61c0ae77f8c>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  contracts['ZONE'] = contracts['ZONE'].astype('str')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New unique values: 23\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8688392 entries, 0 to 9466360\n",
            "Data columns (total 72 columns):\n",
            " #   Column                                         Dtype  \n",
            "---  ------                                         -----  \n",
            " 0   Unnamed: 0                                     int64  \n",
            " 1   ANO_SID                                        float64\n",
            " 2   ORTPLZ                                         int64  \n",
            " 3   CONSTRUCTION_YEAR                              float64\n",
            " 4   WFL                                            float64\n",
            " 5   TYPE_OF_DEDUCTIBLE                             int64  \n",
            " 6   DRAIN_PIPE_INSURED                             int64  \n",
            " 7   PRIOR_DAMAGES                                  int64  \n",
            " 8   UVV-KZ                                         int64  \n",
            " 9   YEAR                                           int64  \n",
            " 10  DAMAGE_HEAVY_RAIN_ZONE                         float64\n",
            " 11  LONGITUDE                                      float64\n",
            " 12  LATITUDE                                       float64\n",
            " 13  DAMAGE                                         int64  \n",
            " 14  CORPORATE_DEVISION_VGV                         bool   \n",
            " 15  CORPORATE_DEVISION_VHV                         bool   \n",
            " 16  CORPORATE_DEVISION_W&W                         bool   \n",
            " 17  Bundesland_Bayern                              bool   \n",
            " 18  Bundesland_Berlin                              bool   \n",
            " 19  Bundesland_Brandenburg                         bool   \n",
            " 20  Bundesland_Bremen                              bool   \n",
            " 21  Bundesland_Hamburg                             bool   \n",
            " 22  Bundesland_Hessen                              bool   \n",
            " 23  Bundesland_Mecklenburg-Vorpommern              bool   \n",
            " 24  Bundesland_Niedersachsen                       bool   \n",
            " 25  Bundesland_Nordrhein-Westfalen                 bool   \n",
            " 26  Bundesland_Rheinland-Pfalz                     bool   \n",
            " 27  Bundesland_Saarland                            bool   \n",
            " 28  Bundesland_Sachsen                             bool   \n",
            " 29  Bundesland_Sachsen-Anhalt                      bool   \n",
            " 30  Bundesland_Schleswig-Holstein                  bool   \n",
            " 31  Bundesland_Thüringen                           bool   \n",
            " 32  Typ_Stadt                                      bool   \n",
            " 33  CONSTRACTION_DESIGN_CARAVAN_MOTORHOME          bool   \n",
            " 34  CONSTRACTION_DESIGN_DESIGN_CLASS_I             bool   \n",
            " 35  CONSTRACTION_DESIGN_DESIGN_CLASS_II            bool   \n",
            " 36  CONSTRACTION_DESIGN_DESIGN_CLASS_III           bool   \n",
            " 37  CONSTRACTION_DESIGN_DESIGN_CLASS_IV            bool   \n",
            " 38  CONSTRACTION_DESIGN_DESIGN_CLASS_V             bool   \n",
            " 39  CONSTRACTION_DESIGN_NORMAL_VENTURE             bool   \n",
            " 40  CONSTRACTION_DESIGN_PREDOMINANTLY_WOODEN_ROOF  bool   \n",
            " 41  CONSTRACTION_DESIGN_PREFAB_HOUSE               bool   \n",
            " 42  CONSTRACTION_DESIGN_UNKNOWN                    bool   \n",
            " 43  ZONE_0.0                                       bool   \n",
            " 44  ZONE_1                                         bool   \n",
            " 45  ZONE_1.0                                       bool   \n",
            " 46  ZONE_2                                         bool   \n",
            " 47  ZONE_2.0                                       bool   \n",
            " 48  ZONE_3                                         bool   \n",
            " 49  ZONE_3.0                                       bool   \n",
            " 50  ZONE_4                                         bool   \n",
            " 51  ZONE_4.0                                       bool   \n",
            " 52  ZONE_5                                         bool   \n",
            " 53  ZONE_5.0                                       bool   \n",
            " 54  ZONE_6                                         bool   \n",
            " 55  ZONE_6.0                                       bool   \n",
            " 56  ZONE_7                                         bool   \n",
            " 57  ZONE_7.0                                       bool   \n",
            " 58  ZONE_8                                         bool   \n",
            " 59  ZONE_8.0                                       bool   \n",
            " 60  ZONE_A                                         bool   \n",
            " 61  ZONE_B                                         bool   \n",
            " 62  ZONE_C                                         bool   \n",
            " 63  ZONE_D                                         bool   \n",
            " 64  ZONE_E                                         bool   \n",
            " 65  PRODUCTLINE_Kompakt                            bool   \n",
            " 66  PRODUCTLINE_Plus                               bool   \n",
            " 67  PRODUCTLINE_Premium                            bool   \n",
            " 68  PRODUCTLINE_Sonst                              bool   \n",
            " 69  PRODUCTLINE_Top                                bool   \n",
            " 70  PRODUCTLINE_UNKNOWN                            bool   \n",
            " 71  UNDERWRITER_Y                                  bool   \n",
            "dtypes: bool(58), float64(6), int64(8)\n",
            "memory usage: 1.4 GB\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing from Francesca\n",
        "# Clean data that is not needed for the model (or would be too hard to encode)\n",
        "#contracts = contract_class.drop(['Unnamed: 0', 'SF-SYSTEM',  'ORTS-NAME', 'STRASSE', 'PARTY-ID', 'contract_year',\n",
        "                          #  'Kreis', 'DAMAGE_FLOOD_ZONE', 'SUM_INSURED', 'PIPE_PREMIUM_AMOUNT', 'LONGITUDE',   ], axis=1)\n",
        "contracts = contract_class.dropna()\n",
        "\n",
        "# Convert all zone values to string (to reduce amount of unique values)\n",
        "print('Original unique values:', contracts['ZONE'].nunique())\n",
        "contracts['ZONE'] = contracts['ZONE'].astype('str')\n",
        "print('New unique values:', contracts['ZONE'].nunique())\n",
        "\n",
        "# Prepare binary variables\n",
        "columns_to_encode = contracts.select_dtypes(include=['object']).columns\n",
        "df_binary = pd.get_dummies(contracts, columns=columns_to_encode, drop_first=True)\n",
        "# Replace negative values with zeros\n",
        "df_binary[df_binary < 0] = 0\n",
        "df_binary.info()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_binary.drop(columns=['DAMAGE', 'ANO_SID' ])\n",
        "y = df_binary['DAMAGE']\n",
        "\n",
        "# Separate continuous and discrete features\n",
        "continuous_features = ['CONSTRUCTION_YEAR','DAMAGE_HEAVY_RAIN_ZONE' ]\n",
        "# The discrete features need to be adjusted after one-hot encoding\n",
        "discrete_features = list(set(X.columns) - set(continuous_features))\n",
        "\n",
        "# Ensure indices are aligned\n",
        "contracts = contracts.reset_index(drop=True)\n",
        "X = X.reset_index(drop=True)\n",
        "y = y.reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for negative values\n",
        "if (X_train_resampled[discrete_features] < 0).any().any():\n",
        "    print(\"Negative values found in X_train_resampled for discrete features\")\n",
        "# Check for negative values in the training data for discrete features\n",
        "negative_values = X_train_resampled[discrete_features] < 0\n",
        "    # Extract and display the negative values\n",
        "negative_values_df = X_train_resampled[discrete_features][negative_values]\n",
        "print(\"Negative values in X_train_resampled:\")\n",
        "print(negative_values_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrSXJnPmxTiC",
        "outputId": "91acb4dc-da5c-4c74-c3ea-35bb7e8645a8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative values in X_train_resampled:\n",
            "        ZONE_B ZONE_1.0 ZONE_2 Bundesland_Berlin  WFL  \\\n",
            "2941709    NaN      NaN    NaN               NaN  NaN   \n",
            "5201100    NaN      NaN    NaN               NaN  NaN   \n",
            "5592555    NaN      NaN    NaN               NaN  NaN   \n",
            "4891623    NaN      NaN    NaN               NaN  NaN   \n",
            "6033584    NaN      NaN    NaN               NaN  NaN   \n",
            "...        ...      ...    ...               ...  ...   \n",
            "3709730    NaN      NaN    NaN               NaN  NaN   \n",
            "5940216    NaN      NaN    NaN               NaN  NaN   \n",
            "2579374    NaN      NaN    NaN               NaN  NaN   \n",
            "3551931    NaN      NaN    NaN               NaN  NaN   \n",
            "3483251    NaN      NaN    NaN               NaN  NaN   \n",
            "\n",
            "        CONSTRACTION_DESIGN_DESIGN_CLASS_III Typ_Stadt ZONE_7.0  \\\n",
            "2941709                                  NaN       NaN      NaN   \n",
            "5201100                                  NaN       NaN      NaN   \n",
            "5592555                                  NaN       NaN      NaN   \n",
            "4891623                                  NaN       NaN      NaN   \n",
            "6033584                                  NaN       NaN      NaN   \n",
            "...                                      ...       ...      ...   \n",
            "3709730                                  NaN       NaN      NaN   \n",
            "5940216                                  NaN       NaN      NaN   \n",
            "2579374                                  NaN       NaN      NaN   \n",
            "3551931                                  NaN       NaN      NaN   \n",
            "3483251                                  NaN       NaN      NaN   \n",
            "\n",
            "        CONSTRACTION_DESIGN_PREFAB_HOUSE Bundesland_Hamburg  ... ZONE_3.0  \\\n",
            "2941709                              NaN                NaN  ...      NaN   \n",
            "5201100                              NaN                NaN  ...      NaN   \n",
            "5592555                              NaN                NaN  ...      NaN   \n",
            "4891623                              NaN                NaN  ...      NaN   \n",
            "6033584                              NaN                NaN  ...      NaN   \n",
            "...                                  ...                ...  ...      ...   \n",
            "3709730                              NaN                NaN  ...      NaN   \n",
            "5940216                              NaN                NaN  ...      NaN   \n",
            "2579374                              NaN                NaN  ...      NaN   \n",
            "3551931                              NaN                NaN  ...      NaN   \n",
            "3483251                              NaN                NaN  ...      NaN   \n",
            "\n",
            "        Bundesland_Mecklenburg-Vorpommern ZONE_5.0  Bundesland_Hessen  \\\n",
            "2941709                               NaN      NaN                NaN   \n",
            "5201100                               NaN      NaN                NaN   \n",
            "5592555                               NaN      NaN                NaN   \n",
            "4891623                               NaN      NaN                NaN   \n",
            "6033584                               NaN      NaN                NaN   \n",
            "...                                   ...      ...                ...   \n",
            "3709730                               NaN      NaN                NaN   \n",
            "5940216                               NaN      NaN                NaN   \n",
            "2579374                               NaN      NaN                NaN   \n",
            "3551931                               NaN      NaN                NaN   \n",
            "3483251                               NaN      NaN                NaN   \n",
            "\n",
            "        PRODUCTLINE_Kompakt ZONE_8.0 Bundesland_Schleswig-Holstein ZONE_6  \\\n",
            "2941709                 NaN      NaN                           NaN    NaN   \n",
            "5201100                 NaN      NaN                           NaN    NaN   \n",
            "5592555                 NaN      NaN                           NaN    NaN   \n",
            "4891623                 NaN      NaN                           NaN    NaN   \n",
            "6033584                 NaN      NaN                           NaN    NaN   \n",
            "...                     ...      ...                           ...    ...   \n",
            "3709730                 NaN      NaN                           NaN    NaN   \n",
            "5940216                 NaN      NaN                           NaN    NaN   \n",
            "2579374                 NaN      NaN                           NaN    NaN   \n",
            "3551931                 NaN      NaN                           NaN    NaN   \n",
            "3483251                 NaN      NaN                           NaN    NaN   \n",
            "\n",
            "         CORPORATE_DEVISION_VHV LATITUDE  \n",
            "2941709                     NaN      NaN  \n",
            "5201100                     NaN      NaN  \n",
            "5592555                     NaN      NaN  \n",
            "4891623                     NaN      NaN  \n",
            "6033584                     NaN      NaN  \n",
            "...                         ...      ...  \n",
            "3709730                     NaN      NaN  \n",
            "5940216                     NaN      NaN  \n",
            "2579374                     NaN      NaN  \n",
            "3551931                     NaN      NaN  \n",
            "3483251                     NaN      NaN  \n",
            "\n",
            "[4664210 rows x 68 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame named 'contracts'\n",
        "unique_values = df_binary['PRODUCTLINE_Kompakt'].unique()\n",
        "print(\"Unique values in CONSTRUCTION_DESIGN_PREFAB_HOUSE:\")\n",
        "print(unique_values)\n",
        "\n",
        "# Count NaN values in the specific column 'CONSTRUCTION_DESIGN_PREFAB_HOUSE'\n",
        "nan_count = df_binary['PRODUCTLINE_Kompakt'].isna().sum()\n",
        "print(f\"Number of NaN values in 'CONSTRUCTION_DESIGN_PREFAB_HOUSE': {nan_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipTm-duoyNE6",
        "outputId": "4b988a23-24ff-4503-b8e4-a95ba126d175"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in CONSTRUCTION_DESIGN_PREFAB_HOUSE:\n",
            "[False  True]\n",
            "Number of NaN values in 'CONSTRUCTION_DESIGN_PREFAB_HOUSE': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAJITJ_Eosnd"
      },
      "source": [
        "## Naive Bayes with expanding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTjSjOWoF5u",
        "outputId": "f4d2099c-6062-4893-9e77-6ccab4cb8071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2015:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92    745209\n",
            "           1       0.04      0.61      0.07      7391\n",
            "\n",
            "    accuracy                           0.85    752600\n",
            "   macro avg       0.52      0.73      0.50    752600\n",
            "weighted avg       0.99      0.85      0.91    752600\n",
            "\n",
            "Confusion Matrix for year 2015:\n",
            "[[633981 111228]\n",
            " [  2885   4506]]\n",
            "True Positives: 4506\n",
            "False Positives: 111228\n",
            "True Negatives: 633981\n",
            "False Negatives: 2885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:13<02:03, 13.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2016:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90    769344\n",
            "           1       0.04      0.65      0.07      8184\n",
            "\n",
            "    accuracy                           0.82    777528\n",
            "   macro avg       0.52      0.73      0.48    777528\n",
            "weighted avg       0.99      0.82      0.89    777528\n",
            "\n",
            "Confusion Matrix for year 2016:\n",
            "[[631241 138103]\n",
            " [  2878   5306]]\n",
            "True Positives: 5306\n",
            "False Positives: 138103\n",
            "True Negatives: 631241\n",
            "False Negatives: 2878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:29<01:58, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2017:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.90    780650\n",
            "           1       0.04      0.62      0.07      8290\n",
            "\n",
            "    accuracy                           0.82    788940\n",
            "   macro avg       0.52      0.72      0.49    788940\n",
            "weighted avg       0.99      0.82      0.89    788940\n",
            "\n",
            "Confusion Matrix for year 2017:\n",
            "[[644707 135943]\n",
            " [  3165   5125]]\n",
            "True Positives: 5125\n",
            "False Positives: 135943\n",
            "True Negatives: 644707\n",
            "False Negatives: 3165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:46<01:52, 16.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2018:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.82      0.90    783954\n",
            "           1       0.04      0.63      0.08      9706\n",
            "\n",
            "    accuracy                           0.82    793660\n",
            "   macro avg       0.52      0.73      0.49    793660\n",
            "weighted avg       0.98      0.82      0.89    793660\n",
            "\n",
            "Confusion Matrix for year 2018:\n",
            "[[641381 142573]\n",
            " [  3557   6149]]\n",
            "True Positives: 6149\n",
            "False Positives: 142573\n",
            "True Negatives: 641381\n",
            "False Negatives: 3557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:06<01:44, 17.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2019:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.81      0.89    786671\n",
            "           1       0.04      0.65      0.08     10428\n",
            "\n",
            "    accuracy                           0.81    797099\n",
            "   macro avg       0.52      0.73      0.49    797099\n",
            "weighted avg       0.98      0.81      0.88    797099\n",
            "\n",
            "Confusion Matrix for year 2019:\n",
            "[[636728 149943]\n",
            " [  3675   6753]]\n",
            "True Positives: 6753\n",
            "False Positives: 149943\n",
            "True Negatives: 636728\n",
            "False Negatives: 3675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:27<01:33, 18.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2020:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.80      0.89    789930\n",
            "           1       0.05      0.66      0.09     12053\n",
            "\n",
            "    accuracy                           0.80    801983\n",
            "   macro avg       0.52      0.73      0.49    801983\n",
            "weighted avg       0.98      0.80      0.87    801983\n",
            "\n",
            "Confusion Matrix for year 2020:\n",
            "[[632648 157282]\n",
            " [  4038   8015]]\n",
            "True Positives: 8015\n",
            "False Positives: 157282\n",
            "True Negatives: 632648\n",
            "False Negatives: 4038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:50<01:20, 20.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2021:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.78      0.88    792523\n",
            "           1       0.05      0.68      0.09     13256\n",
            "\n",
            "    accuracy                           0.78    805779\n",
            "   macro avg       0.52      0.73      0.48    805779\n",
            "weighted avg       0.98      0.78      0.86    805779\n",
            "\n",
            "Confusion Matrix for year 2021:\n",
            "[[621479 171044]\n",
            " [  4214   9042]]\n",
            "True Positives: 9042\n",
            "False Positives: 171044\n",
            "True Negatives: 621479\n",
            "False Negatives: 4214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:14<01:04, 21.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2022:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.77      0.87    800472\n",
            "           1       0.04      0.71      0.08     11489\n",
            "\n",
            "    accuracy                           0.77    811961\n",
            "   macro avg       0.52      0.74      0.47    811961\n",
            "weighted avg       0.98      0.77      0.86    811961\n",
            "\n",
            "Confusion Matrix for year 2022:\n",
            "[[615490 184982]\n",
            " [  3350   8139]]\n",
            "True Positives: 8139\n",
            "False Positives: 184982\n",
            "True Negatives: 615490\n",
            "False Negatives: 3350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:41<00:46, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2023:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86    805948\n",
            "           1       0.03      0.72      0.07      9672\n",
            "\n",
            "    accuracy                           0.76    815620\n",
            "   macro avg       0.52      0.74      0.46    815620\n",
            "weighted avg       0.98      0.76      0.85    815620\n",
            "\n",
            "Confusion Matrix for year 2023:\n",
            "[[611884 194064]\n",
            " [  2691   6981]]\n",
            "True Positives: 6981\n",
            "False Positives: 194064\n",
            "True Negatives: 611884\n",
            "False Negatives: 2691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:09<00:24, 24.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for year 2024:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86    814414\n",
            "           1       0.01      0.72      0.01      1866\n",
            "\n",
            "    accuracy                           0.75    816280\n",
            "   macro avg       0.50      0.74      0.44    816280\n",
            "weighted avg       1.00      0.75      0.86    816280\n",
            "\n",
            "Confusion Matrix for year 2024:\n",
            "[[613634 200780]\n",
            " [   518   1348]]\n",
            "True Positives: 1348\n",
            "False Positives: 200780\n",
            "True Negatives: 613634\n",
            "False Negatives: 518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:41<00:00, 22.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Confusion Matrix:\n",
            "[[6283173 1585942]\n",
            " [  30971   61364]]\n",
            "Combined True Positives: 61364\n",
            "Combined False Positives: 1585942\n",
            "Combined True Negatives: 6283173\n",
            "Combined False Negatives: 30971\n",
            "Combined Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89   7869115\n",
            "           1       0.04      0.66      0.07     92335\n",
            "\n",
            "    accuracy                           0.80   7961450\n",
            "   macro avg       0.52      0.73      0.48   7961450\n",
            "weighted avg       0.98      0.80      0.88   7961450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define parameter grids for GaussianNB and MultinomialNB\n",
        "gnb_param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
        "}\n",
        "\n",
        "mnb_param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "# Create a list of unique years in the data\n",
        "years = sorted(contracts['YEAR'].unique())\n",
        "\n",
        "# Initialize lists to store results\n",
        "recall_scores = []\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "# Loop over each year for expanding window estimation\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "    test_year = years[i + 1]\n",
        "    train_years = years[:i + 1]  # All years up to and including the year before test_year\n",
        "\n",
        "    # Split data into training and testing sets based on year\n",
        "    train_indices = contracts['YEAR'].isin(train_years)\n",
        "    test_indices = contracts['YEAR'] == test_year\n",
        "\n",
        "    X_train = X[train_indices].reset_index(drop=True)\n",
        "    y_train = y[train_indices].reset_index(drop=True)\n",
        "    X_test = X[test_indices].reset_index(drop=True)\n",
        "    y_test = y[test_indices].reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # Resample classes to ratio 1:5 in the training data\n",
        "    train = pd.concat([X_train, y_train], axis=1)\n",
        "    class_0 = train[train['DAMAGE'] == 0]\n",
        "    class_1 = train[train['DAMAGE'] == 1]\n",
        "\n",
        "\n",
        "\n",
        "    n_samples_0 = len(class_0) // 2  # Undersample class 0 to half its size\n",
        "    n_samples_1 = n_samples_0 // 5   # Oversample class 1 to be 1/5 of the undersampled class 0\n",
        "\n",
        "    # Resample class 0 (undersample)\n",
        "    class_0_resampled = resample(class_0,\n",
        "                                 replace=False,\n",
        "                                 n_samples=n_samples_0,\n",
        "                                 random_state=42)\n",
        "\n",
        "    # Resample class 1 (oversample)\n",
        "    class_1_resampled = resample(class_1,\n",
        "                                 replace=True,\n",
        "                                 n_samples=n_samples_1,\n",
        "                                 random_state=42)\n",
        "\n",
        "    # Combine the resampled classes\n",
        "    train_resampled = pd.concat([class_0_resampled, class_1_resampled])\n",
        "    X_train_resampled = train_resampled.drop(columns='DAMAGE')\n",
        "    y_train_resampled = train_resampled['DAMAGE']\n",
        "\n",
        "    # Train ComplementNB on discrete features\n",
        "    cnb = ComplementNB()\n",
        "    cnb.fit(X_train_resampled[continuous_features], y_train_resampled)\n",
        "\n",
        "# Train BernoulliNB on binary features\n",
        "    bnb = BernoulliNB()\n",
        "    bnb.fit(X_train_resampled[discrete_features], y_train_resampled)\n",
        "\n",
        "   # Get predicted probabilities for discrete features using ComplementNB\n",
        "    cnb_prob = cnb.predict_proba(X_test[continuous_features])[:, 1]\n",
        "\n",
        "# Get predicted probabilities for binary features using BernoulliNB\n",
        "    bnb_prob = bnb.predict_proba(X_test[discrete_features])[:, 1]\n",
        "\n",
        "    # Combine probabilities (you can average them, use weighted sum, etc.)\n",
        "    combined_prob = (cnb_prob + bnb_prob) / 2\n",
        "\n",
        "    # Convert probabilities to binary predictions based on a threshold (e.g., 0.5)\n",
        "    y_pred = (combined_prob >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate accuracy for the current year\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate recall score\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    recall_scores.append((test_year, recall))\n",
        "\n",
        "    # Print the classification report for each year\n",
        "    print(f\"Classification report for year {test_year}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Generating confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix for year {test_year}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Extracting TP, FP, TN, FN from the confusion matrix\n",
        "    TN = conf_matrix[0][0]\n",
        "    FP = conf_matrix[0][1]\n",
        "    FN = conf_matrix[1][0]\n",
        "    TP = conf_matrix[1][1]\n",
        "\n",
        "    # Printing TP, FP, TN, FN\n",
        "    print(\"True Positives:\", TP)\n",
        "    print(\"False Positives:\", FP)\n",
        "    print(\"True Negatives:\", TN)\n",
        "    print(\"False Negatives:\", FN)\n",
        "\n",
        "    # Accumulate true and predicted values\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "    # Create a DataFrame for the probabilities\n",
        "    probabilities_df = pd.DataFrame({'Probability': combined_prob})\n",
        "\n",
        "    # Combine the probabilities with the original test data for the year\n",
        "    combined_df = contracts[contracts['YEAR'] == test_year].copy()\n",
        "    combined_df['Probability'] = probabilities_df['Probability'].values\n",
        "\n",
        "    # Save the combined DataFrame to a CSV file\n",
        "    combined_df.to_csv(f'probabilities_{test_year}.csv', index=False)\n",
        "\n",
        "# Calculate and print the combined confusion matrix and classification report\n",
        "combined_conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "print(\"Combined Confusion Matrix:\")\n",
        "print(combined_conf_matrix)\n",
        "\n",
        "# Extract and print TP, FP, TN, FN from the combined confusion matrix\n",
        "combined_TN = combined_conf_matrix[0][0]\n",
        "combined_FP = combined_conf_matrix[0][1]\n",
        "combined_FN = combined_conf_matrix[1][0]\n",
        "combined_TP = combined_conf_matrix[1][1]\n",
        "\n",
        "print(\"Combined True Positives:\", combined_TP)\n",
        "print(\"Combined False Positives:\", combined_FP)\n",
        "print(\"Combined True Negatives:\", combined_TN)\n",
        "print(\"Combined False Negatives:\", combined_FN)\n",
        "\n",
        "combined_class_report = classification_report(all_y_true, all_y_pred)\n",
        "print(\"Combined Classification Report:\")\n",
        "print(combined_class_report)\n",
        "\n",
        "\n",
        "# Combine all the CSV files into a single DataFrame\n",
        "#combined_all_years = pd.concat([pd.read_csv(f'probabilities_{year}.csv') for year in years[1:]])\n",
        "\n",
        "# Save the combined DataFrame to a CSV file\n",
        "#combined_all_years.to_csv('/content/drive/MyDrive/Colab Notebooks/Capstone_Data/Capstone/Data/NaiveBayes.csv', index=False)\n",
        "# Print recall scores\n",
        "#for year, score in recall_scores:\n",
        "    #print(f\"Year: {year}, Recall Score: {score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM70t3QkHyTlrw9xR5+iiFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}