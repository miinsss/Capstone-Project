{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6436ac-cfa8-4fe2-a51a-fb4e3a2514a0",
   "metadata": {},
   "source": [
    "# Balance the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4a217-d62d-4874-9033-d0caf6e95cd0",
   "metadata": {},
   "source": [
    "## Installations and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f61f9a-616d-4e66-b0f4-4a602c275ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: dask[complete]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "!pip install dask[complete] dask-ml imbalanced-learn\n",
    "\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.preprocessing import DummyEncoder\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65256bbf-a39a-48f8-a861-5cb5e5a1bb10",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497b81c1-4869-4d15-8b5e-3a82da1d1277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/minarandolf/Capstone/Capstone-Project/datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/ct286z0d1tz0s971c6b7qshh0000gn/T/ipykernel_32551/3493101213.py:10: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 11574439\n",
      "Column names:\n",
      "Index(['ANO_SID', 'CORPORATE_DEVISION', 'ORTPLZ', 'ORTS-NAME', 'STRASSE',\n",
      "       'SUM_INSURED', 'CONSTRACTION_DESIGN', 'CONSTRUCTION_YEAR', 'WFL',\n",
      "       'ZONE', 'SF-SYSTEM', 'TYPE_OF_DEDUCTIBLE', 'DRAIN_PIPE_INSURED',\n",
      "       'PRODUCTLINE', 'PRIOR_DAMAGES', 'UVV-KZ', 'UNDERWRITER', 'PARTY-ID',\n",
      "       'contract_year', 'PIPE_PREMIUM_AMOUNT', 'YEAR', 'DAMAGE'],\n",
      "      dtype='object')\n",
      "Column types:\n",
      "ANO_SID                float64\n",
      "CORPORATE_DEVISION      object\n",
      "ORTPLZ                 float64\n",
      "ORTS-NAME               object\n",
      "STRASSE                 object\n",
      "SUM_INSURED            float64\n",
      "CONSTRACTION_DESIGN     object\n",
      "CONSTRUCTION_YEAR      float64\n",
      "WFL                    float64\n",
      "ZONE                    object\n",
      "SF-SYSTEM              float64\n",
      "TYPE_OF_DEDUCTIBLE       int64\n",
      "DRAIN_PIPE_INSURED       int64\n",
      "PRODUCTLINE             object\n",
      "PRIOR_DAMAGES            int64\n",
      "UVV-KZ                   int64\n",
      "UNDERWRITER             object\n",
      "PARTY-ID                object\n",
      "contract_year           object\n",
      "PIPE_PREMIUM_AMOUNT    float64\n",
      "YEAR                     int64\n",
      "DAMAGE                   int64\n",
      "dtype: object\n",
      "     ANO_SID CORPORATE_DEVISION   ORTPLZ  ORTS-NAME               STRASSE  \\\n",
      "0  4114028.0                VHV  42109.0  Wuppertal     Hans-BÃ¶ckler-Str.   \n",
      "1  4114039.0                VHV  42277.0  Wuppertal       Liegnitzer Str.   \n",
      "2  4114045.0                VHV  42389.0  Wuppertal             Rascheweg   \n",
      "3  4114049.0                VGV  42277.0  Wuppertal               Am Diek   \n",
      "4  4114055.0                VHV  42553.0    Velbert  Emil-Schniewind-Str.   \n",
      "\n",
      "   SUM_INSURED CONSTRACTION_DESIGN  CONSTRUCTION_YEAR        WFL ZONE  ...  \\\n",
      "0      71081.0      NORMAL_VENTURE        1967.565648   69.00000  2.0  ...   \n",
      "1      55708.0      NORMAL_VENTURE        1967.565648   65.00000  4.0  ...   \n",
      "2      74148.0      DESIGN_CLASS_I        1967.565648   75.00000  1.0  ...   \n",
      "3     664000.0      NORMAL_VENTURE        1967.565648  106.24368  NaN  ...   \n",
      "4      75682.0      NORMAL_VENTURE        1967.565648  119.00000  2.0  ...   \n",
      "\n",
      "   DRAIN_PIPE_INSURED  PRODUCTLINE  PRIOR_DAMAGES UVV-KZ  UNDERWRITER  \\\n",
      "0                   0        Sonst              0      1            Y   \n",
      "1                   0        Basis              0      1            Y   \n",
      "2                   0        Sonst              0      1            Y   \n",
      "3                   0      Kompakt              0      1            Y   \n",
      "4                   0        Sonst              0      1            Y   \n",
      "\n",
      "               PARTY-ID contract_year PIPE_PREMIUM_AMOUNT  YEAR  DAMAGE  \n",
      "0  N00WXYAWXFD704PT4712    2014-01-01             4.55070  2014       0  \n",
      "1  YH8XZ8AWXFD704PT4713    2014-01-01             4.54080  2014       0  \n",
      "2  AIPAVQEWXFD704PT4713    2014-01-01             3.18120  2014       0  \n",
      "3  GG0UA4KWXFD704PT4715    2014-01-01           154.60908  2014       0  \n",
      "4  P6XU2FAWXFD704PT4712    2014-01-01             5.89380  2014       0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "# Check the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Define the path to your CSV file\n",
    "file_path = '/Users/minarandolf/Capstone/Capstone-Project/datasets/contract_undersampling.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Number of observations: {len(df)}\")\n",
    "    print(\"Column names:\")\n",
    "    print(df.columns)\n",
    "    print(\"Column types:\")\n",
    "    print(df.dtypes)\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {file_path} does not exist in the current working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d93142-43de-47ed-9a5e-7c459da7a8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for each class in 'DAMAGE':\n",
      "DAMAGE\n",
      "0    11389665\n",
      "1      184774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution of each class in 'DAMAGE':\n",
      "DAMAGE\n",
      "0    98.403603\n",
      "1     1.596397\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis\n",
    "# Count the occurrences of each class in the target variable 'DAMAGE'\n",
    "damage_counts = df['DAMAGE'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of observations for each class in 'DAMAGE':\")\n",
    "print(damage_counts)\n",
    "\n",
    "# Display the percentage distribution\n",
    "damage_percentage = df['DAMAGE'].value_counts(normalize=True) * 100\n",
    "print(\"\\nPercentage distribution of each class in 'DAMAGE':\")\n",
    "print(damage_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d806a9-ad01-415f-a1cf-7a1ffce3814e",
   "metadata": {},
   "source": [
    "## Balance the Data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c51c432-554a-4f7e-9746-ba4f74c4daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to load data in chunks and apply SMOTE incrementally\n",
    "def load_and_balance_data(file_path, chunk_size=100000):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    balanced_data_X = []\n",
    "    balanced_data_y = []\n",
    "\n",
    "    # Process data in chunks\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        # Convert 'contract_year' to datetime\n",
    "        chunk['contract_year'] = pd.to_datetime(chunk['contract_year'], errors='coerce')\n",
    "\n",
    "        # Drop rows with NaN values in 'contract_year'\n",
    "        chunk = chunk.dropna(subset=['contract_year'])\n",
    "        \n",
    "        # Separate features and target\n",
    "        X_chunk = chunk.drop('DAMAGE', axis=1)\n",
    "        y_chunk = chunk['DAMAGE']\n",
    "        \n",
    "        # Convert categorical columns to dummy variables\n",
    "        categorical_columns = ['CORPORATE_DEVISION', 'ORTS-NAME', 'STRASSE', 'CONSTRACTION_DESIGN', 'ZONE', 'PRODUCTLINE', 'UNDERWRITER', 'PARTY-ID']\n",
    "        X_chunk = pd.get_dummies(X_chunk, columns=categorical_columns, drop_first=True)\n",
    "        \n",
    "        # Ensure numeric columns are in correct format\n",
    "        X_chunk = X_chunk.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        \n",
    "        # Apply SMOTE to the chunk\n",
    "        X_resampled_chunk, y_resampled_chunk = smote.fit_resample(X_chunk, y_chunk)\n",
    "        \n",
    "        balanced_data_X.append(X_resampled_chunk)\n",
    "        balanced_data_y.append(y_resampled_chunk)\n",
    "    \n",
    "    # Concatenate all the resampled chunks\n",
    "    X_resampled = np.vstack(balanced_data_X)\n",
    "    y_resampled = np.hstack(balanced_data_y)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1753aa-f97b-47cd-8871-3aa5ffa39f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
